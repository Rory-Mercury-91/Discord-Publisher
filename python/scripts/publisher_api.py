"""
API Publisher - Version Bot Discord Hybride avec Contr√¥le de Versions
- API REST pour publication depuis l'application frontend
- Bot Discord avec commandes slash pour contr√¥le manuel
- T√¢che quotidienne automatique √† 6h pour contr√¥le des versions F95
- Modification automatique des posts + notifications group√©es
"""

import os
import sys
import json
import time
import base64
import asyncio
import logging
import datetime
import random
import secrets
import re
from datetime import datetime as dt
from typing import Optional, Tuple, List, Dict
from pathlib import Path
from zoneinfo import ZoneInfo
import hashlib
from dataclasses import dataclass
import aiohttp
from aiohttp import web
from dotenv import load_dotenv

# ==================== LOGGING ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] [%(name)s] %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("publisher")

# Discord imports
import discord
from discord.ext import commands, tasks
from discord import app_commands

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# Charger .env : _ignored/ prioritaire, puis racine python/
from pathlib import Path as _Path
_python_dir = _Path(__file__).resolve().parent.parent
load_dotenv(_python_dir / "_ignored" / ".env")
load_dotenv(_python_dir / ".env")

# ==================== SUPABASE (source de v√©rit√© published_posts) ====================
# Import au niveau module pour √©viter le lazy loading bloquant
try:
    from supabase import create_client
    _SUPABASE_AVAILABLE = True
except ImportError:
    _SUPABASE_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Module supabase non install√©")

_supabase_client = None

def _init_supabase():
    """Initialise le client Supabase au d√©marrage (non-bloquant pour l'event loop)."""
    global _supabase_client
    if not _SUPABASE_AVAILABLE:
        return None
    url = (os.getenv("SUPABASE_URL") or "").strip()
    # Service Role Key pour le serveur (bypass RLS) ; fallback sur Anon Key si absente
    key = (os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_ANON_KEY") or "").strip()
    if not url or not key:
        logger.info("‚ÑπÔ∏è Supabase non configur√© (SUPABASE_URL ou SUPABASE_SERVICE_ROLE_KEY/SUPABASE_ANON_KEY manquants)")
        return None
    try:
        _supabase_client = create_client(url, key)
        logger.info("‚úÖ Client Supabase initialis√©")
        return _supabase_client
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è √âchec initialisation Supabase: {e}")
        return None

def _get_supabase():
    """Retourne le client Supabase (d√©j√† initialis√© au d√©marrage)."""
    return _supabase_client


def _delete_from_supabase_sync(thread_id: str = None, post_id: str = None) -> bool:
    """
    üî• Supprime un post de Supabase par thread_id ou post_id (synchrone).
    Retourne True si la suppression a r√©ussi, False sinon.
    """
    sb = _get_supabase()
    if not sb:
        logger.warning("‚ö†Ô∏è Client Supabase non initialis√©")
        return False
    
    if not thread_id and not post_id:
        logger.warning("‚ö†Ô∏è Aucun identifiant fourni pour la suppression Supabase")
        return False
    
    try:
        # API Supabase Python: .delete() AVANT .eq()
        if post_id:
            result = sb.table("published_posts").delete().eq("id", post_id).execute()
        else:
            result = sb.table("published_posts").delete().eq("thread_id", str(thread_id)).execute()
        
        # V√©rifier le r√©sultat
        deleted_count = len(result.data) if result.data else 0
        
        if deleted_count > 0:
            logger.info(f"‚úÖ {deleted_count} post(s) supprim√©(s) de Supabase (thread_id={thread_id}, id={post_id})")
            return True
        else:
            logger.info(f"‚ÑπÔ∏è Aucun post trouv√© dans Supabase avec thread_id={thread_id} ou id={post_id}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la suppression Supabase: {e}")
        return False


def _fetch_post_by_thread_id_sync(thread_id) -> Optional[Dict]:
    """R√©cup√®re la ligne published_posts par thread_id (source de v√©rit√©). Retourne None si absent."""
    sb = _get_supabase()
    if not sb:
        return None
    try:
        r = sb.table("published_posts").select("*").eq("thread_id", str(thread_id)).order("updated_at", desc=True).limit(1).execute()
        if r.data and len(r.data) > 0:
            return r.data[0]
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Supabase fetch_post_by_thread_id: {e}")
    return None


def _parse_saved_inputs(row: Dict) -> Dict:
    """Retourne saved_inputs comme dict (parse si Supabase renvoie une cha√Æne json)."""
    raw = row.get("saved_inputs")
    if raw is None:
        return {}
    if isinstance(raw, dict):
        return raw
    if isinstance(raw, str):
        try:
            return json.loads(raw) if raw.strip() else {}
        except Exception:
            return {}
    return {}


def _metadata_from_row(row: Dict, new_game_version: Optional[str] = None) -> Optional[str]:
    """Construit metadata_b64 √† partir d'une ligne published_posts (saved_inputs + colonnes)."""
    saved = _parse_saved_inputs(row)
    version = new_game_version if new_game_version is not None else (saved.get("Game_version") or "")
    metadata = {
        "game_name": (saved.get("Game_name") or row.get("title") or "").strip(),
        "game_version": version.strip(),
        "translate_version": (saved.get("Translate_version") or "").strip(),
        "translation_type": (row.get("translation_type") or "").strip(),
        "is_integrated": bool(row.get("is_integrated", False)),
        "timestamp": int(time.time() * 1000),
    }
    try:
        metadata_json = json.dumps(metadata, ensure_ascii=False)
        return base64.b64encode(metadata_json.encode("utf-8")).decode("utf-8")
    except Exception:
        return None

# ==================== CONFIGURATION ====================
class Config:
    def __init__(self):
        # API REST
        self.PUBLISHER_DISCORD_TOKEN = os.getenv("PUBLISHER_DISCORD_TOKEN", "")
        self.PUBLISHER_API_KEY = os.getenv("PUBLISHER_API_KEY", "")
        self.ALLOWED_ORIGINS = os.getenv("PUBLISHER_ALLOWED_ORIGINS", "*")
        self.PORT = int(os.getenv("PORT", "8080"))
        # API Discord officielle (https://discord.com/api/v10) ‚Äî le serveur Oracle communique en direct
        self.DISCORD_API_BASE = os.getenv("DISCORD_API_BASE", "https://discord.com/api/v10")
        
        # Salon unique "my" : forum qui re√ßoit les posts (publication + contr√¥le versions)
        self.FORUM_MY_ID = int(os.getenv("PUBLISHER_FORUM_TRAD_ID", "0")) if os.getenv("PUBLISHER_FORUM_TRAD_ID") else 0
        if not self.FORUM_MY_ID and os.getenv("FORUM_CHANNEL_ID"):
            self.FORUM_MY_ID = int(os.getenv("FORUM_CHANNEL_ID", "0"))
        
        # Salon qui re√ßoit les notifications de mise √† jour de version
        self.PUBLISHER_MAJ_NOTIFICATION_CHANNEL_ID = int(os.getenv("PUBLISHER_MAJ_NOTIFICATION_CHANNEL_ID", "0")) if os.getenv("PUBLISHER_MAJ_NOTIFICATION_CHANNEL_ID") else 0
        # Salon qui re√ßoit les annonces (nouvelle traduction / mise √† jour)
        self.PUBLISHER_ANNOUNCE_CHANNEL_ID = int(os.getenv("PUBLISHER_ANNOUNCE_CHANNEL_ID", "0")) if os.getenv("PUBLISHER_ANNOUNCE_CHANNEL_ID") else 0
        
        # Planification
        self.VERSION_CHECK_HOUR = int(os.getenv("VERSION_CHECK_HOUR", "6"))
        self.VERSION_CHECK_MINUTE = int(os.getenv("VERSION_CHECK_MINUTE", "0"))
        self.CLEANUP_EMPTY_MESSAGES_HOUR = int(os.getenv("CLEANUP_EMPTY_MESSAGES_HOUR", "4"))
        self.CLEANUP_EMPTY_MESSAGES_MINUTE = int(os.getenv("CLEANUP_EMPTY_MESSAGES_MINUTE", "0"))
        
        self.configured = bool(
            self.PUBLISHER_DISCORD_TOKEN and
            self.FORUM_MY_ID and
            self.PUBLISHER_MAJ_NOTIFICATION_CHANNEL_ID
        )
    
    def update_from_frontend(self, config_data: dict):
        if 'discordPublisherToken' in config_data and config_data['discordPublisherToken']:
            self.PUBLISHER_DISCORD_TOKEN = config_data['discordPublisherToken']
        if 'publisherForumMyId' in config_data and config_data['publisherForumMyId']:
            self.FORUM_MY_ID = int(config_data['publisherForumMyId'])
        self.configured = bool(self.PUBLISHER_DISCORD_TOKEN and self.FORUM_MY_ID and self.PUBLISHER_MAJ_NOTIFICATION_CHANNEL_ID)
        logger.info(f"‚úÖ Configuration mise √† jour (configured: {self.configured})")

config = Config()
def get_publisher_token() -> str:
    # 1) env > 2) config en m√©moire
    return (os.getenv("PUBLISHER_DISCORD_TOKEN") or config.PUBLISHER_DISCORD_TOKEN or "").strip()

# ==================== DISCORD BOT SETUP ====================
intents = discord.Intents.default()
intents.message_content = True
intents.guilds = True

bot = commands.Bot(command_prefix="!", intents=intents)

# ==================== REGEX PATTERNS ====================
# Pour parsing du contenu texte (fallback si m√©tadonn√©es absentes)
_RE_GAME_VERSION_MD = re.compile(
    r"^\s*\*\s*\*\*Version\s+du\s+jeu\s*:\s*\*\*\s*`(?P<ver>[^`]+)`\s*$",
    re.IGNORECASE | re.MULTILINE
)
_RE_GAME_LINK_MD = re.compile(
    r"^\s*\*\s*\*\*Lien\s+du\s+jeu\s*:\s*\*\*\s*\[.*?\]\(<(?P<url>https?://[^>]+)>\)\s*$",
    re.IGNORECASE | re.MULTILINE
)

# Version sans markdown (format legacy)
_RE_GAME_VERSION_PLAIN = re.compile(
    r"^\s*Version\s+du\s+jeu\s*:\s*`?(?P<ver>[^`\n]+)`?\s*$",
    re.IGNORECASE | re.MULTILINE
)
_RE_GAME_LINK_PLAIN = re.compile(
    r"^\s*Lien\s+du\s+jeu\s*:\s*\[.*?\]\(<(?P<url>https?://[^)>]+)>\)\s*$",
    re.IGNORECASE | re.MULTILINE
)

# Nouveau format (uniquement lien du jeu) : * [Jeu original](<url>) ‚Äî pas les autres liens F95 (traduction, etc.)
_RE_GAME_LINK_JEU_ORIGINAL = re.compile(
    r"^\s*\*\s*\[\s*Jeu\s+original\s*\]\s*\(\s*<\s*(?P<url>https?://[^>]+)\s*>\s*\)\s*$",
    re.IGNORECASE | re.MULTILINE
)

# Extraction version depuis titre F95
_RE_BRACKETS = re.compile(r"\[(?P<val>[^\]]+)\]")
# Version dans le nom du thread Discord (ex: "Growing Problems [v0.12]" -> "v0.12")
# Le groupe ver doit capturer tout le contenu y compris le pr√©fixe "v" pour la comparaison avec F95
_RE_VERSION_IN_THREAD_NAME = re.compile(r"\[(?P<ver>v?[^\]]+)\]\s*$", re.IGNORECASE)


def _build_thread_title_with_version(thread_name: str, new_version: str) -> str:
    """Remplace la r√©f√©rence de version entre crochets √† la fin du titre par la nouvelle version.
    Ex: 'The Legend of the Goblins [Ch.5]' -> 'The Legend of the Goblins [Ch.6]'
    """
    if not (thread_name and new_version):
        return thread_name or ""
    new_title = _RE_VERSION_IN_THREAD_NAME.sub(f"[{new_version}]", thread_name.strip()).strip()
    return new_title or thread_name

# ==================== STOCKAGE ANTI-DOUBLON ====================
# Structure: {thread_id: {"f95_version": "Ch.7", "timestamp": datetime}}
_notified_versions: Dict[int, Dict] = {}

def _clean_old_notifications():
    """Nettoie les entr√©es de plus de 30 jours"""
    cutoff = dt.now() - datetime.timedelta(days=30)
    to_remove = [
        tid for tid, data in _notified_versions.items()
        if data.get("timestamp", dt.min) < cutoff
    ]
    for tid in to_remove:
        del _notified_versions[tid]
    if to_remove:
        logger.info(f"üßπ Nettoyage anti-doublon: {len(to_remove)} entr√©es supprim√©es")

def _is_already_notified(thread_id: int, f95_version: str) -> bool:
    """V√©rifie si cette version a d√©j√† √©t√© notifi√©e pour ce thread"""
    if thread_id not in _notified_versions:
        return False
    return _notified_versions[thread_id].get("f95_version") == f95_version

def _mark_as_notified(thread_id: int, f95_version: str):
    """Marque cette version comme notifi√©e"""
    _notified_versions[thread_id] = {
        "f95_version": f95_version,
        "timestamp": dt.now()
    }

def _normalize_history_row(row: Dict) -> Dict:
    """Garantit les cl√©s snake_case attendues par le frontend (rowToPost)."""
    if not row:
        return row
    # Accepte camelCase entrant et renvoie snake_case pour coh√©rence avec Supabase
    alias = {
        "threadId": "thread_id", "messageId": "message_id", "discordUrl": "discord_url",
        "forumId": "forum_id", "imagePath": "image_path", "translationType": "translation_type",
        "isIntegrated": "is_integrated", "authorDiscordId": "author_discord_id",
        "savedInputs": "saved_inputs", "savedLinkConfigs": "saved_link_configs",
        "savedAdditionalTranslationLinks": "saved_additional_translation_links",
        "savedAdditionalModLinks": "saved_additional_mod_links", "templateId": "template_id",
        "createdAt": "created_at", "updatedAt": "updated_at",
    }
    out = dict(row)
    for camel, snake in alias.items():
        if camel in out and snake not in out:
            out[snake] = out.pop(camel)
    return out

# ==================== RATE LIMIT TRACKER ====================
class RateLimitTracker:
    def __init__(self):
        self.remaining: Optional[int] = None
        self.limit: Optional[int] = None
        self.reset_at: Optional[float] = None
    
    def update_from_headers(self, headers: dict):
        try:
            if 'X-RateLimit-Remaining' in headers:
                self.remaining = int(headers['X-RateLimit-Remaining'])
            if 'X-RateLimit-Limit' in headers:
                self.limit = int(headers['X-RateLimit-Limit'])
            if 'X-RateLimit-Reset' in headers:
                self.reset_at = float(headers['X-RateLimit-Reset'])
            if self.remaining is not None and self.remaining < 5:
                logger.warning(f"‚ö†Ô∏è  Rate limit proche: {self.remaining} requ√™tes restantes")
        except Exception as e:
            logger.error(f"Erreur headers rate limit: {e}")
    
    def get_info(self) -> dict:
        info = {"remaining": self.remaining, "limit": self.limit, "reset_at": self.reset_at, "reset_in_seconds": None}
        if self.reset_at:
            info["reset_in_seconds"] = int(max(0, self.reset_at - time.time()))
        return info

rate_limiter = RateLimitTracker()

# ==================== RATE LIMIT TRACKER ====================

# ==================== CACHE & VALIDATION CL√âS API ====================


# Message d'avertissement renvoy√© au frontend quand l'ancienne cl√© partag√©e est d√©tect√©e
LEGACY_KEY_WARNING = (
    "Votre cl√© API est la cl√© partag√©e (usage obsol√®te). "
    "Tapez /generer-cle sur le serveur Discord pour obtenir votre cl√© personnelle."
)


@dataclass
class _CachedEntry:
    discord_user_id: str   # "" si cl√© refus√©e ou legacy
    discord_name: str      # "" si cl√© refus√©e ou legacy
    is_valid: bool
    expires_at: float      # time.monotonic()


class _ApiKeyCache:
    """
    Cache m√©moire TTL pour les lookups Supabase.
    Asyncio est single-threaded ‚Üí pas besoin de Lock.
    TTL par d√©faut : 5 minutes (configurable via env API_KEY_CACHE_TTL).
    """

    def __init__(self, ttl: int = 300):
        self._store: dict[str, _CachedEntry] = {}
        self._ttl = ttl

    def get(self, key_hash: str) -> "_CachedEntry | None":
        entry = self._store.get(key_hash)
        if not entry:
            return None
        if time.monotonic() > entry.expires_at:
            del self._store[key_hash]
            return None
        return entry

    def set(self, key_hash: str, discord_user_id: str, discord_name: str, is_valid: bool):
        self._store[key_hash] = _CachedEntry(
            discord_user_id=discord_user_id,
            discord_name=discord_name,
            is_valid=is_valid,
            expires_at=time.monotonic() + self._ttl,
        )

    def evict_user(self, discord_user_id: str):
        """Invalide imm√©diatement toutes les entr√©es d'un utilisateur (rotation/r√©vocation)."""
        to_del = [h for h, e in self._store.items() if e.discord_user_id == discord_user_id]
        for h in to_del:
            del self._store[h]
        if to_del:
            logger.info(f"üîë Cache: {len(to_del)} entr√©e(s) invalid√©e(s) pour discord_user_id={discord_user_id}")

    def evict_hash(self, key_hash: str):
        """Invalide imm√©diatement une cl√© sp√©cifique par son hash."""
        if self._store.pop(key_hash, None):
            logger.info("üîë Cache: entr√©e invalid√©e par hash")


_api_key_cache = _ApiKeyCache(
    ttl=int(os.getenv("API_KEY_CACHE_TTL", "300"))
)


def _hash_raw_key(raw_key: str) -> str:
    """SHA-256 hex ‚Äî identique √† la fonction SQL hash_api_key()."""
    return hashlib.sha256(raw_key.encode("utf-8")).hexdigest()


def _update_key_usage_sync(key_hash: str):
    """
    Met √† jour last_used_at + use_count dans Supabase.
    Appel√© via run_in_executor ‚Üí non bloquant pour l'event loop.
    """
    sb = _get_supabase()
    if not sb:
        return
    try:
        # Incr√©mentation atomique via RPC ou UPDATE direct
        sb.table("api_keys").update({
            "last_used_at": datetime.datetime.now(ZoneInfo("UTC")).isoformat(),
        }).eq("key_hash", key_hash).execute()
        # use_count incr√©ment√© s√©par√©ment pour √©viter une race condition
        sb.rpc("increment_key_use_count", {"p_key_hash": key_hash}).execute()
    except Exception as e:
        # Non bloquant : un √©chec de comptage ne doit pas casser une publication
        logger.debug(f"‚ö†Ô∏è Mise √† jour usage cl√© (non critique): {e}")


async def _validate_api_key(
    raw_key: str,
) -> tuple[bool, "str | None", "str | None", bool]:
    """
    Valide une cl√© API re√ßue dans X-API-KEY.

    Retourne : (is_valid, discord_user_id, discord_name, is_legacy)

        is_valid        ‚Üí False = requ√™te rejet√©e (401)
        discord_user_id ‚Üí ID Discord du traducteur, None si legacy ou refus√©
        discord_name    ‚Üí Pseudo Discord, None si legacy ou refus√©
        is_legacy       ‚Üí True = ancienne cl√© partag√©e (accept√©e + warning renvoy√©)

    Ordre de v√©rification :
        1. Cache m√©moire     (< 1 ¬µs, √©vite les round-trips)
        2. Ancienne cl√© partag√©e  (migration en douceur)
        3. Supabase          (lookup par hash)
    """
    if not raw_key:
        return False, None, None, False

    # ‚îÄ‚îÄ 1. Cache ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    key_hash = _hash_raw_key(raw_key)
    cached = _api_key_cache.get(key_hash)
    if cached is not None:
        uid = cached.discord_user_id or None
        name = cached.discord_name or None
        return cached.is_valid, uid, name, False

    # ‚îÄ‚îÄ 2. Ancienne cl√© partag√©e (legacy) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # On ne met PAS en cache pour que le check soit refait √† chaque requ√™te.
    # Ainsi, si PUBLISHER_API_KEY change, l'ancienne cl√© est imm√©diatement rejet√©e.
    if config.PUBLISHER_API_KEY and raw_key == config.PUBLISHER_API_KEY:
        return True, None, None, True  # is_legacy=True

    # ‚îÄ‚îÄ 3. Supabase : nouvelle cl√© individuelle ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    sb = _get_supabase()
    if not sb:
        logger.warning("‚ö†Ô∏è Supabase indisponible ‚Äî validation nouvelle cl√© impossible")
        return False, None, None, False

    try:
        res = (
            sb.table("api_keys")
            .select("discord_user_id, discord_name, is_active")
            .eq("key_hash", key_hash)
            .eq("is_active", True)
            .limit(1)
            .execute()
        )
        if res.data:
            row = res.data[0]
            _api_key_cache.set(key_hash, row["discord_user_id"], row["discord_name"], True)
            # Mise √† jour usage en arri√®re-plan (non bloquant)
            loop = asyncio.get_event_loop()
            loop.run_in_executor(None, _update_key_usage_sync, key_hash)
            return True, row["discord_user_id"], row["discord_name"], False
        else:
            # Cl√© inconnue ou r√©voqu√©e ‚Üí on cache le refus (prot√®ge contre le brute-force)
            _api_key_cache.set(key_hash, "", "", False)
            return False, None, None, False

    except Exception as e:
        logger.error(f"‚ùå Supabase erreur validation cl√©: {e}")
        # Fail-closed : en cas d'erreur Supabase on rejette (s√©curit√© > disponibilit√©)
        return False, None, None, False

# ==================== HELPER RE-ROUTAGE ====================

async def _get_thread_parent_id(session, thread_id: str) -> Optional[str]:
    """R√©cup√®re le parent_id (salon forum) d'un thread via l'API Discord."""
    status, data = await _discord_get(session, f"/channels/{thread_id}")
    if status >= 300 or not isinstance(data, dict):
        logger.warning(f"‚ö†Ô∏è Impossible de r√©cup√©rer le thread {thread_id} (status={status})")
        return None
    return str(data.get("parent_id") or "")


async def _reroute_post(
    session,
    old_thread_id: str,
    old_message_id: str,
    target_forum_id: str,
    title: str,
    content: str,
    tags_raw: str,
    metadata_b64: Optional[str],
) -> Optional[dict]:
    """
    Re-route un post vers le bon salon :
    1. Cr√©e un nouveau thread dans target_forum_id
    2. Supprime l'ancien thread
    3. Retourne les nouvelles infos (thread_id, message_id, thread_url)
    ou None en cas d'√©chec.
    """
    logger.info(f"üîÄ Re-routage: thread {old_thread_id} ‚Üí forum {target_forum_id}")

    # 1. Cr√©er dans le bon salon
    ok, result = await _create_forum_post(
        session, target_forum_id, title, content, tags_raw, [], metadata_b64
    )
    if not ok:
        logger.error(f"‚ùå Re-routage: √©chec cr√©ation dans forum {target_forum_id}: {result}")
        return None

    new_thread_id = result.get("thread_id")
    new_message_id = result.get("message_id")
    new_thread_url = result.get("thread_url", "")

    logger.info(f"‚úÖ Re-routage: nouveau thread cr√©√© ‚Üí {new_thread_id}")

    # 2. Supprimer l'ancien thread
    deleted, del_status = await _discord_delete_channel(session, old_thread_id)
    if not deleted:
        if del_status == 404:
            logger.info(f"‚ÑπÔ∏è Re-routage: ancien thread d√©j√† supprim√© ({old_thread_id})")
        else:
            logger.warning(f"‚ö†Ô∏è Re-routage: √©chec suppression ancien thread {old_thread_id} (status={del_status})")
            # On continue quand m√™me ‚Äî le nouveau post est cr√©√©

    return {
        "thread_id": new_thread_id,
        "message_id": new_message_id,
        "thread_url": new_thread_url,
        "rerouted": True,
        "old_thread_id": old_thread_id,
    }
# ‚îÄ‚îÄ Helper : extraction + validation en une ligne pour les handlers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def _auth_request(request, route: str) -> "tuple[bool, str|None, str|None, bool]":
    """
    Utilis√© en t√™te de chaque handler prot√©g√©.
    Retourne (is_valid, discord_user_id, discord_name, is_legacy).
    Loggue automatiquement les √©checs d'auth.
    """
    raw_key = (request.headers.get("X-API-KEY") or request.query.get("api_key") or "").strip()
    is_valid, uid, name, is_legacy = await _validate_api_key(raw_key)
    if not is_valid:
        client_ip = _get_client_ip(request)
        logger.warning(f"[AUTH] üö´ √âchec auth depuis {client_ip} (route: {route})")
    return is_valid, uid, name, is_legacy

def _build_forum_link(thread_url: str, forum_id: int = None) -> Optional[str]:
    """
    D√©rive l'URL du forum depuis l'URL d'un thread.
    Utilise forum_id si fourni, sinon fallback sur config.FORUM_MY_ID.
    """
    actual_forum_id = forum_id or config.FORUM_MY_ID
    if not thread_url or not actual_forum_id:
        return None
    parts = thread_url.rstrip("/").split("/")
    if len(parts) < 2:
        return None
    guild_id = parts[-2]
    if not guild_id.isdigit():
        return None
    return f"https://discord.com/channels/{guild_id}/{actual_forum_id}"

# ==================== UTILITAIRES ====================
def _b64decode_padded(s: str) -> bytes:
    """D√©codage base64 tol√©rant (padding manquant, espaces, etc.)."""
    s = (s or "").strip()
    if not s:
        return b""
    missing = (-len(s)) % 4
    if missing:
        s += "=" * missing
    return base64.b64decode(s)

def _decode_metadata_b64(metadata_b64: str) -> Optional[Dict]:
    """D√©code les m√©tadonn√©es encod√©es en base64."""
    if not metadata_b64:
        return None
    raw = _b64decode_padded(metadata_b64)
    s = raw.decode("utf-8")
    try:
        return json.loads(s)
    except json.JSONDecodeError:
        import urllib.parse
        return json.loads(urllib.parse.unquote(s))

def _extract_f95_thread_id(url: str) -> Optional[str]:
    """
    Extrait l'ID num√©rique d'un thread F95Zone.
    Accepte les URLs avec /post-XXXXX (ex: .../threads/game.8012/post-11944222 -> "8012").

    Examples:
        https://f95zone.to/threads/game-name.285451/ -> "285451"
        https://f95zone.to/threads/285451 -> "285451"
        https://f95zone.to/threads/milfy-city-v1-0e-icstor.8012/post-11944222 -> "8012"

    Returns:
        L'ID num√©rique comme string, ou None si non trouv√©
    """
    if not url:
        return None
    # [^/]*\. pour capturer le slug avant le point, (\d+) pour l'ID (compatible /post-XXXXX)
    pattern = r'/threads/(?:[^/]*\.)?(\d+)'
    match = re.search(pattern, url)
    return match.group(1) if match else None

async def fetch_f95_versions_by_ids(session: aiohttp.ClientSession, thread_ids: list) -> Dict[str, str]:
    """
    üÜï NOUVELLE M√âTHODE: R√©cup√®re les versions depuis l'API F95 checker.php
    Plus fiable et rapide que le parsing HTML !
    
    ‚ö†Ô∏è LIMITE API F95: Maximum 100 IDs par requ√™te
    Cette fonction d√©coupe automatiquement en blocs de 50 IDs pour la s√©curit√©
    
    Args:
        session: Session aiohttp
        thread_ids: Liste des IDs de threads F95 (ex: ["100", "285451"])
    
    Returns:
        Dict {thread_id: version}
        Example: {"100": "v0.68", "285451": "Ch.7"}
    """
    if not thread_ids:
        return {}
    
    # ‚ö†Ô∏è LIMITE API: Maximum 100 IDs, on utilise des chunks de 50 par s√©curit√©
    CHUNK_SIZE = 50
    total_ids = len(thread_ids)
    all_versions = {}
    
    logger.info(f"üì° F95 API: R√©cup√©ration pour {total_ids} threads (par blocs de {CHUNK_SIZE})")
    
    # D√©couper en chunks de 50 IDs
    for chunk_idx in range(0, total_ids, CHUNK_SIZE):
        chunk = thread_ids[chunk_idx:chunk_idx + CHUNK_SIZE]
        chunk_num = (chunk_idx // CHUNK_SIZE) + 1
        total_chunks = (total_ids + CHUNK_SIZE - 1) // CHUNK_SIZE
        
        logger.info(f"üì° Bloc {chunk_num}/{total_chunks}: {len(chunk)} IDs")
        
        # Construire l'URL pour ce chunk
        ids_str = ",".join(str(tid) for tid in chunk)
        checker_url = f"https://f95zone.to/sam/checker.php?threads={ids_str}"
        
        try:
            async with session.get(checker_url, timeout=aiohttp.ClientTimeout(total=30)) as resp:
                if resp.status != 200:
                    logger.warning(f"‚ö†Ô∏è F95 Checker API HTTP {resp.status} pour le bloc {chunk_num}")
                    continue  # Passer au chunk suivant
                
                data = await resp.json()
                
                if data.get("status") == "ok" and "msg" in data:
                    chunk_versions = data["msg"]
                    logger.info(f"‚úÖ Bloc {chunk_num}: {len(chunk_versions)} versions r√©cup√©r√©es")
                    all_versions.update(chunk_versions)
                else:
                    logger.warning(f"‚ö†Ô∏è Bloc {chunk_num}: r√©ponse invalide")
                    
        except Exception as e:
            logger.warning(f"‚ùå Erreur bloc {chunk_num}: {e}")
        
        # Petit d√©lai entre les requ√™tes pour ne pas surcharger l'API
        if chunk_idx + CHUNK_SIZE < total_ids:
            await asyncio.sleep(1)
    
    logger.info(f"‚úÖ F95 API: TOTAL {len(all_versions)}/{total_ids} versions r√©cup√©r√©es")
    return all_versions

def _normalize_version(version: str) -> str:
    """Normalise une version pour la comparaison (enl√®ve backticks, espaces inutiles)"""
    if not version:
        return ""
    # Enlever backticks
    normalized = version.strip().replace('`', '')
    # Normaliser les espaces
    normalized = re.sub(r'\s+', ' ', normalized)
    return normalized.strip()


def _extract_version_from_thread_name(thread_name: str) -> Optional[str]:
    """Extrait la version depuis le nom du thread Discord (ex: 'Growing Problems [v0.12]' -> 'v0.12')."""
    if not (thread_name or isinstance(thread_name, str)):
        return None
    m = _RE_VERSION_IN_THREAD_NAME.search(thread_name.strip())
    return m.group("ver").strip() if m else None

async def _collect_all_forum_threads(forum: discord.ForumChannel) -> List[discord.Thread]:
    """
    Retourne TOUS les threads d'un forum :
    - Actifs (forum.threads)
    - Archiv√©s publics (forum.archived_threads)
    """
    all_threads: Dict[int, discord.Thread] = {}

    # 1) Threads actifs (cache)
    for t in list(getattr(forum, "threads", []) or []):
        all_threads[t.id] = t

    # 2) Threads archiv√©s publics (pagination)
    if hasattr(forum, "archived_threads"):
        before = None
        while True:
            batch = []
            try:
                async for t in forum.archived_threads(limit=100, before=before):
                    batch.append(t)
            except TypeError:
                # Compat si la signature diff√®re
                async for t in forum.archived_threads(limit=100):
                    batch.append(t)

            if not batch:
                break

            for t in batch:
                all_threads[t.id] = t

            # Pagination
            before = batch[-1].archive_timestamp or batch[-1].created_at
            await asyncio.sleep(0.8)

            if before is None:
                break

    return list(all_threads.values())

# ==================== EXTRACTION M√âTADONN√âES/CONTENU ====================
async def _extract_post_data(thread: discord.Thread) -> Tuple[Optional[str], Optional[str]]:
    """
    Extrait (game_link, game_version) depuis un thread Discord.
    Priorit√© : Supabase (published_posts) > m√©tadonn√©es embed > parsing texte
    Returns:
        (game_link, game_version) ou (None, None) si non trouv√©
    """
    # 1) Priorit√© : ligne published_posts par thread_id (source de v√©rit√©)
    loop = asyncio.get_event_loop()
    row = await loop.run_in_executor(None, _fetch_post_by_thread_id_sync, thread.id)
    if row:
        saved = _parse_saved_inputs(row)
        game_version = (saved.get("Game_version") or "").strip()
        # Le nom du thread Discord est mis √† jour par forum_post_update ; priorit√© √† cette version (√©tat live)
        version_from_thread_name = _extract_version_from_thread_name(getattr(thread, "name", "") or "")
        if version_from_thread_name:
            game_version = _normalize_version(version_from_thread_name)
            logger.info(f"üìå Version post pour {thread.name}: {game_version} (depuis nom du thread)")
        elif game_version:
            game_version = _normalize_version(game_version)
            logger.info(f"üìå Version post pour {thread.name}: {game_version}")
        content = (row.get("content") or "") or ""
        game_link = None
        m_link_md = _RE_GAME_LINK_MD.search(content)
        m_link_plain = _RE_GAME_LINK_PLAIN.search(content)
        if m_link_md:
            game_link = m_link_md.group("url").strip()
        elif m_link_plain:
            game_link = m_link_plain.group("url").strip()
        if not game_link:
            # Nouveau format : * [Jeu original](<url>) ‚Äî ligne d√©di√©e, pas les autres liens F95
            m_jeu = _RE_GAME_LINK_JEU_ORIGINAL.search(content)
            if m_jeu:
                game_link = m_jeu.group("url").strip()
        if game_link or game_version:
            logger.info(f"‚úÖ Donn√©es post depuis Supabase (thread_id={thread.id})")
            return game_link, game_version

    # 2) Fallback : message Discord (m√©tadonn√©es embed ou parsing)
    msg = thread.starter_message
    if not msg:
        try:
            await asyncio.sleep(0.8)
            msg = thread.starter_message or await thread.fetch_message(thread.id)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible de r√©cup√©rer le message de d√©part pour {thread.name}: {e}")
            return None, None
    
    if not msg:
        return None, None
    
    game_link = None
    game_version = None
    
    # 1Ô∏è‚É£ PRIORIT√â : M√©tadonn√©es de l'embed invisible
    if msg.embeds:
        for embed in msg.embeds:
            footer_text = embed.footer.text if embed.footer else ""
            
            # V√©rifier si c'est notre embed de m√©tadonn√©es
            if footer_text and footer_text.startswith("metadata:v1:"):
                logger.info(f"üì¶ M√©tadonn√©es d√©tect√©es pour {thread.name}")
                
                # Reconstruction du metadata_b64 depuis les fields
                chunks = []
                for field in embed.fields:
                    if field.name == "\u200b":  # Notre marqueur invisible
                        chunks.append(field.value)
                
                if chunks:
                    metadata_b64 = "".join(chunks)
                    try:
                        metadata = _decode_metadata_b64(metadata_b64)
                        if metadata:
                            # Extraire game_version depuis les m√©tadonn√©es
                            # Note: les m√©tadonn√©es contiennent game_version (version du jeu)
                            game_version = metadata.get("game_version", "")
                            
                            # Pour game_link, on doit parser le contenu texte car ce n'est pas dans les m√©tadonn√©es
                            # Les m√©tadonn√©es contiennent : game_name, game_version, translate_version, traductor, etc.
                            # mais pas game_link
                            logger.info(f"‚úÖ Version extraite des m√©tadonn√©es: {game_version}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erreur d√©codage m√©tadonn√©es pour {thread.name}: {e}")
    
    # 2Ô∏è‚É£ FALLBACK : Parsing du contenu texte
    content = (msg.content if msg else "") or ""
    
    # Extraire game_link (toujours depuis le texte car absent des m√©tadonn√©es)
    m_link_md = _RE_GAME_LINK_MD.search(content)
    m_link_plain = _RE_GAME_LINK_PLAIN.search(content)
    if m_link_md:
        game_link = m_link_md.group("url").strip()
    elif m_link_plain:
        game_link = m_link_plain.group("url").strip()
    if not game_link:
        # Nouveau format : * [Jeu original](<url>) ‚Äî ligne d√©di√©e, pas les autres liens F95
        m_jeu = _RE_GAME_LINK_JEU_ORIGINAL.search(content)
        if m_jeu:
            game_link = m_jeu.group("url").strip()
    
    # Si game_version n'a pas √©t√© trouv√©e dans les m√©tadonn√©es, parser le texte
    if not game_version:
        m_ver_md = _RE_GAME_VERSION_MD.search(content)
        m_ver_plain = _RE_GAME_VERSION_PLAIN.search(content)
        
        if m_ver_md:
            game_version = m_ver_md.group("ver").strip()
        elif m_ver_plain:
            game_version = m_ver_plain.group("ver").strip()
    
    # Normaliser la version
    if game_version:
        game_version = _normalize_version(game_version)
    
    if game_link:
        logger.info(f"üîó Lien extrait pour {thread.name}: {game_link}")
    if game_version:
        logger.info(f"üìå Version post pour {thread.name}: {game_version}")
    
    return game_link, game_version

# ==================== MODIFICATION POST ====================
def _embed_preserve_dict(embed: discord.Embed) -> dict:
    """
    Convertit un embed en dict en pr√©servant explicitement image, thumbnail et tous les champs
    visuels pour un round-trip sans perte (ex: image du post qui ne doit pas dispara√Ætre au MAJ version).
    """
    d = embed.to_dict()
    # S'assurer que l'image est bien pr√©sente (embed cr√©√© c√¥t√© Discord peut avoir une structure diff√©rente)
    if getattr(embed, "image", None) and getattr(embed.image, "url", None):
        d["image"] = {"url": str(embed.image.url)}
    if getattr(embed, "thumbnail", None) and getattr(embed.thumbnail, "url", None):
        d["thumbnail"] = {"url": str(embed.thumbnail.url)}
    return d


async def _update_post_version(thread: discord.Thread, new_version: str) -> bool:
    """
    Met √† jour la version du jeu dans le post Discord (contenu + m√©tadonn√©es).
    Pr√©serve tous les √©l√©ments existants : image(s), embeds non-m√©tadonn√©es, etc.
    Priorit√© : construire les m√©tadonn√©es depuis Supabase (published_posts), sinon depuis l'embed Discord.
    Returns:
        True si succ√®s, False sinon
    """
    try:
        msg = thread.starter_message
        if not msg:
            msg = await thread.fetch_message(thread.id)
        if not msg:
            logger.error(f"‚ùå Message introuvable pour {thread.name}")
            return False

        content = msg.content or ""
        new_content = _RE_GAME_VERSION_MD.sub(
            f"* **Version du jeu :** `{new_version}`",
            content
        )
        if new_content == content:
            new_content = _RE_GAME_VERSION_PLAIN.sub(
                f"Version du jeu : `{new_version}`",
                content
            )

        # M√©tadonn√©es : priorit√© Supabase (row), sinon embed Discord
        metadata_b64_new = None
        loop = asyncio.get_event_loop()
        row = await loop.run_in_executor(None, _fetch_post_by_thread_id_sync, thread.id)
        if row:
            metadata_b64_new = _metadata_from_row(row, new_game_version=new_version)
            if metadata_b64_new:
                logger.info(f"‚úÖ M√©tadonn√©es construites depuis Supabase pour {thread.name}")

        if not metadata_b64_new and msg.embeds:
            for embed in msg.embeds:
                footer_text = embed.footer.text if embed.footer else ""
                if footer_text and footer_text.startswith("metadata:v1:"):
                    chunks = []
                    for field in embed.fields:
                        if field.name == "\u200b":
                            chunks.append(field.value)
                    if chunks:
                        metadata_b64 = "".join(chunks)
                        metadata = _decode_metadata_b64(metadata_b64)
                        if metadata:
                            metadata["game_version"] = new_version
                            metadata["timestamp"] = int(time.time() * 1000)
                            metadata_json = json.dumps(metadata, ensure_ascii=False)
                            metadata_b64_new = base64.b64encode(metadata_json.encode("utf-8")).decode("utf-8")
                    break

        # Conserver uniquement les embeds non-m√©tadonn√©es (image, etc.) sur le message principal.
        # Les m√©tadonn√©es vont dans un 2e message s√©par√© (comme √† la cr√©ation) puis SUPPRESS pour le masquer.
        new_embeds = []
        for embed in msg.embeds:
            footer_text = embed.footer.text if embed.footer else ""
            if footer_text and footer_text.startswith("metadata:v1:"):
                # Ne pas copier l'embed m√©tadonn√©es sur le message principal
                continue
            new_embeds.append(_embed_preserve_dict(embed))

        try:
            await msg.edit(content=new_content, embeds=[discord.Embed.from_dict(e) for e in new_embeds])

            # Mettre √† jour ou cr√©er le message m√©tadonn√©es s√©par√© (2e message), puis le masquer (SUPPRESS)
            if metadata_b64_new and len(metadata_b64_new) <= 25000:
                metadata_message = None
                async for m in thread.history(limit=30):
                    if m.id == msg.id:
                        continue
                    for e in m.embeds:
                        ft = e.footer.text if e.footer else ""
                        if ft and ft.startswith("metadata:v1:"):
                            metadata_message = m
                            break
                    if metadata_message:
                        break
                if metadata_message:
                    await metadata_message.edit(
                        content=" ",
                        embeds=[discord.Embed.from_dict(_build_metadata_embed(metadata_b64_new))]
                    )
                    try:
                        await metadata_message.edit(suppress=True)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Impossible de masquer l'embed m√©tadonn√©es: {e}")
                    logger.info(f"‚úÖ Message m√©tadonn√©es mis √† jour et masqu√© pour {thread.name}")
                else:
                    # Cr√©er un 2e message avec les m√©tadonn√©es puis le masquer
                    sent = await thread.send(
                        content=" ",
                        embeds=[discord.Embed.from_dict(_build_metadata_embed(metadata_b64_new))]
                    )
                    try:
                        await sent.edit(suppress=True)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Impossible de masquer le nouvel embed m√©tadonn√©es: {e}")
                    logger.info(f"‚úÖ Message m√©tadonn√©es cr√©√© et masqu√© pour {thread.name}")

            # Mettre √† jour le titre du thread Discord : r√©f√©rence entre crochets -> nouvelle version (ex: "Jeu [Ch.5]" -> "Jeu [Ch.6]")
            new_title = _build_thread_title_with_version(thread.name, new_version)
            if new_title != thread.name:
                try:
                    await thread.edit(name=new_title)
                    logger.info(f"‚úÖ Titre du thread mis √† jour: {thread.name} -> {new_title}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de renommer le thread {thread.name}: {e}")
            # Mettre √† jour published_posts sur Supabase pour que l'historique reste align√©
            if row:
                sb = _get_supabase()
                if sb:
                    try:
                        saved = _parse_saved_inputs(row)
                        saved["Game_version"] = new_version
                        updates = {
                            "title": new_title,
                            "saved_inputs": saved,
                            "updated_at": datetime.datetime.now(ZoneInfo("UTC")).isoformat(),
                        }
                        sb.table("published_posts").update(updates).eq("id", row["id"]).execute()
                        logger.info(f"‚úÖ published_posts mis √† jour sur Supabase pour {thread.name}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è √âchec mise √† jour Supabase published_posts: {e}")
            logger.info(f"‚úÖ Post mis √† jour pour {thread.name}: {new_version}")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur modification message pour {thread.name}: {e}")
            return False
    except Exception as e:
        logger.error(f"‚ùå Erreur mise √† jour post {thread.name}: {e}")
        return False

# ==================== ALERTES VERSIONS ====================
class VersionAlert:
    """Repr√©sente une alerte de version (salon my uniquement)"""
    def __init__(self, thread_name: str, thread_url: str, f95_version: Optional[str],
                 post_version: Optional[str], updated: bool):
        self.thread_name = thread_name
        self.thread_url = thread_url
        self.f95_version = f95_version
        self.post_version = post_version
        self.updated = updated

async def _group_and_send_alerts(channel: discord.TextChannel, alerts: List[VersionAlert]):
    """Envoie les alertes (max 10 par message)"""
    if not alerts:
        return
    title = f"üö® **Mises √† jour d√©tect√©es** ({len(alerts)} jeux)"
    for i in range(0, len(alerts), 10):
        batch = alerts[i:i+10]
        msg_parts = [title, ""]
        for alert in batch:
            if alert.f95_version:
                msg_parts.append(
                    f"**{alert.thread_name}**\n"
                    f"‚îú Version F95 : `{alert.f95_version}`\n"
                    f"‚îú Version du poste : `{alert.post_version or 'Non renseign√©e'}`\n"
                    f"‚îú Version modifi√©e : {'OUI ‚úÖ' if alert.updated else 'NON ‚ùå'}\n"
                    f"‚îî Lien : {alert.thread_url}\n"
                )
            else:
                msg_parts.append(
                    f"**{alert.thread_name}**\n"
                    f"‚îú Version F95 : Non d√©tectable ‚ö†Ô∏è\n"
                    f"‚îú Version du poste : `{alert.post_version or 'Non renseign√©e'}`\n"
                    f"‚îú Version modifi√©e : NON\n"
                    f"‚îî Lien : {alert.thread_url}\n"
                )
        await channel.send("\n".join(msg_parts))
        await asyncio.sleep(1.5)

# ==================== CONTR√îLE VERSIONS F95 ====================
async def run_version_check_once():
    """
    üÜï Contr√¥le des versions F95 via l'API checker.php (salon my uniquement)
    AM√âLIORATION: Utilise l'API au lieu du parsing HTML pour plus de fiabilit√© !
    """
    logger.info("üîé D√©marrage contr√¥le versions F95 (salon my) - M√©thode API")
    channel_notif = bot.get_channel(config.PUBLISHER_MAJ_NOTIFICATION_CHANNEL_ID)
    if not channel_notif:
        logger.error("‚ùå Salon notifications MAJ introuvable")
        return
    if not config.FORUM_MY_ID:
        logger.warning("‚ö†Ô∏è PUBLISHER_FORUM_TRAD_ID non configur√©")
        return
    
    _clean_old_notifications()
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Accept": "application/json,*/*",
    }
    
    all_alerts: List[VersionAlert] = []
    forum = bot.get_channel(config.FORUM_MY_ID)
    if not forum:
        logger.warning(f"‚ö†Ô∏è Forum {config.FORUM_MY_ID} introuvable")
        return
    
    threads = await _collect_all_forum_threads(forum)
    logger.info(f"üîé Check version F95: {len(threads)} threads (actifs + archiv√©s)")
    
    # üìä PHASE 1: Collecter tous les IDs F95 depuis les threads Discord
    thread_mapping = {}  # {f95_id: (thread, post_version)}
    
    async with aiohttp.ClientSession(headers=headers) as session:
        for thread in threads:
            await asyncio.sleep(0.3)  # Anti-spam Discord
            
            game_link, post_version = await _extract_post_data(thread)
            if not game_link or not post_version:
                logger.debug(f"‚è≠Ô∏è  Thread ignor√© (donn√©es manquantes): {thread.name}")
                continue
            
            if "lewdcorner.com" in game_link.lower():
                logger.debug(f"‚è≠Ô∏è  Thread ignor√© (LewdCorner): {thread.name}")
                continue
            
            if "f95zone.to" not in game_link.lower():
                logger.debug(f"‚è≠Ô∏è  Thread ignor√© (non-F95Zone): {thread.name}")
                continue
            
            # Extraire l'ID F95
            f95_id = _extract_f95_thread_id(game_link)
            if not f95_id:
                logger.warning(f"‚ö†Ô∏è Impossible d'extraire l'ID F95 depuis: {game_link}")
                continue
            
            thread_mapping[f95_id] = (thread, post_version)
            logger.info(f"‚úÖ Thread mapp√©: {thread.name} ‚Üí F95 ID {f95_id}")
        
        if not thread_mapping:
            logger.info("‚úÖ Aucun thread avec lien F95 trouv√©")
            return
        
        # üöÄ PHASE 2: R√©cup√©rer toutes les versions via l'API (1 seule requ√™te !)
        f95_ids = list(thread_mapping.keys())
        logger.info(f"üåê R√©cup√©ration API F95 pour {len(f95_ids)} threads...")
        
        f95_versions = await fetch_f95_versions_by_ids(session, f95_ids)
        
        if not f95_versions:
            logger.warning("‚ö†Ô∏è Aucune version r√©cup√©r√©e depuis l'API F95")
            return
        
        # üéØ PHASE 3: Comparaison des versions
        for f95_id, api_version in f95_versions.items():
            if f95_id not in thread_mapping:
                continue
            
            thread, post_version = thread_mapping[f95_id]
            
            # Normaliser les versions
            api_version_clean = _normalize_version(api_version)
            post_version_clean = _normalize_version(post_version)
            
            if api_version_clean != post_version_clean:
                if not _is_already_notified(thread.id, api_version_clean):
                    logger.info(f"üîÑ Diff√©rence: {thread.name}: F95={api_version_clean} vs Post={post_version_clean}")
                    update_success = await _update_post_version(thread, api_version_clean)
                    all_alerts.append(VersionAlert(thread.name, thread.jump_url, api_version_clean, post_version_clean, update_success))
                    _mark_as_notified(thread.id, api_version_clean)
            else:
                logger.info(f"‚úÖ Version OK: {thread.name} ({post_version_clean})")
    
    await _group_and_send_alerts(channel_notif, all_alerts)
    logger.info(f"üìä Contr√¥le termin√© : {len(all_alerts)} alertes envoy√©es")

# ==================== NETTOYAGE MESSAGES VIDES ====================
async def run_cleanup_empty_messages_once():
    """
    Supprime les messages vides dans les threads de TOUS les salons configur√©s 
    (Mappings, Externes et salon par d√©faut).
    """
    logger.info("üßπ D√©marrage nettoyage global des messages vides")
    
    # 1. R√©cup√©ration de tous les IDs de forums uniques depuis Supabase
    from publisher_api import _get_supabase
    sb = _get_supabase()
    forum_ids = set()

    # On ajoute le salon MY par d√©faut s'il est configur√©
    if config.FORUM_MY_ID:
        forum_ids.add(str(config.FORUM_MY_ID))

    if sb:
        try:
            # R√©cup√©ration des mappings profils inscrits
            r1 = sb.table("translator_forum_mappings").select("forum_channel_id").execute()
            for row in (r1.data or []):
                val = str(row.get("forum_channel_id", "")).strip()
                if val and val != "0":
                    forum_ids.add(val)

            # R√©cup√©ration des traducteurs externes
            r2 = sb.table("external_translators").select("forum_channel_id").execute()
            for row in (r2.data or []):
                val = str(row.get("forum_channel_id", "")).strip()
                if val and val != "0":
                    forum_ids.add(val)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des salons Supabase pour nettoyage: {e}")

    if not forum_ids:
        logger.warning("‚ö†Ô∏è Aucun salon trouv√© pour le nettoyage.")
        return

    logger.info(f"üìÇ {len(forum_ids)} salon(s) √† analyser pour le nettoyage")
    
    total_deleted = 0
    async with aiohttp.ClientSession() as session:
        for forum_id_str in forum_ids:
            try:
                forum_id = int(forum_id_str)
                forum = bot.get_channel(forum_id)
                
                if not forum:
                    logger.warning(f"‚ö†Ô∏è Salon {forum_id} introuvable ou inaccessible par le bot")
                    continue

                logger.info(f"üìÅ Nettoyage du salon: {forum.name} ({forum_id})")
                
                # R√©cup√©ration de tous les threads du salon (actifs + archiv√©s)
                threads = await _collect_all_forum_threads(forum)
                if not threads:
                    continue

                for thread_idx, thread in enumerate(threads, 1):
                    # Petit d√©lai pour √©viter le spam API Discord
                    await asyncio.sleep(0.5 + random.random())
                    
                    n = await _clean_empty_messages_in_thread(session, str(thread.id))
                    total_deleted += n
                    
                    if thread_idx % 10 == 0:
                        logger.info(f"üìä [{forum.name}] Progression: {thread_idx}/{len(threads)} threads trait√©s")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du traitement du salon {forum_id_str}: {e}")

    logger.info(f"‚úÖ Nettoyage global termin√© : {total_deleted} message(s) vide(s) supprim√©(s) sur {len(forum_ids)} salons.")

# ==================== T√ÇCHE QUOTIDIENNE ====================
@tasks.loop(time=datetime.time(hour=config.VERSION_CHECK_HOUR, minute=config.VERSION_CHECK_MINUTE, tzinfo=ZoneInfo("Europe/Paris")))
async def daily_version_check():
    """Contr√¥le quotidien automatique √† l'heure configur√©e (d√©faut: 6h Europe/Paris)"""
    logger.info(f"üïï D√©marrage contr√¥le quotidien automatique des versions F95")
    try:
        await run_version_check_once()
    except Exception as e:
        logger.error(f"‚ùå Erreur contr√¥le quotidien: {e}")

@tasks.loop(time=datetime.time(hour=config.CLEANUP_EMPTY_MESSAGES_HOUR, minute=config.CLEANUP_EMPTY_MESSAGES_MINUTE, tzinfo=ZoneInfo("Europe/Paris")))
async def daily_cleanup_empty_messages():
    """Nettoyage quotidien des messages vides dans les threads (d√©faut: 4h Europe/Paris)."""
    logger.info("üßπ D√©marrage nettoyage quotidien des messages vides")
    try:
        await run_cleanup_empty_messages_once()
    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage messages vides: {e}")

@tasks.loop(hours=2)
async def sync_jeux_task():
    """Synchronise les jeux depuis f95fr vers la table Supabase f95_jeux (toutes les 2h)."""
    logger.info("‚è∞ [sync_jeux] Synchronisation automatique toutes les 2h...")
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(
                F95FR_API_URL,
                headers={"X-API-KEY": F95FR_API_KEY},
                timeout=aiohttp.ClientTimeout(total=60)
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    if isinstance(data, list) and data:
                        loop = asyncio.get_event_loop()
                        await loop.run_in_executor(None, _sync_jeux_to_supabase, data)
                        logger.info(f"‚úÖ [sync_jeux] {len(data)} jeux synchronis√©s dans f95_jeux")
                    else:
                        logger.warning("[sync_jeux] R√©ponse vide ou invalide")
                else:
                    logger.warning(f"‚ö†Ô∏è [sync_jeux] API f95fr HTTP {resp.status}")
    except Exception as e:
        logger.error(f"‚ùå [sync_jeux] Erreur: {e}")

# ==================== COMMANDES SLASH ====================

# Lire l'ID du r√¥le autoris√© depuis .env
TRANSLATOR_ROLE_ID = int(os.getenv("TRANSLATOR_ROLE_ID", "0")) if os.getenv("TRANSLATOR_ROLE_ID") else 0


async def _user_can_run_checks(interaction: discord.Interaction) -> bool:
    """
    V√©rifie de mani√®re fiable si l'utilisateur poss√®de le r√¥le TRANSLATOR_ROLE_ID.
    Utilise fetch_member pour contourner les probl√®mes de cache.
    """
    if not TRANSLATOR_ROLE_ID or not interaction.guild:
        return False
    try:
        # On force la r√©cup√©ration du membre aupr√®s de Discord (asynchrone)
        member = await interaction.guild.fetch_member(interaction.user.id)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è [_user_can_run_checks] Impossible de fetch_member pour {interaction.user.id}: {e}")
        return False
    if not member:
        return False
    # V√©rification du r√¥le ou si c'est le propri√©taire du serveur
    has_role = any(r.id == TRANSLATOR_ROLE_ID for r in member.roles)
    is_owner = member.id == interaction.guild.owner_id
    return bool(has_role or is_owner)


def _generate_raw_key() -> str:
    """G√©n√®re une cl√© API lisible et unique. Format : tr_<32 hex chars>"""
    return f"tr_{secrets.token_hex(16)}"


def _revoke_existing_key_sync(discord_user_id: str) -> bool:
    """
    R√©voque la cl√© active existante d'un utilisateur (sync, via run_in_executor).
    Retourne True si une cl√© a √©t√© r√©voqu√©e, False si l'utilisateur n'en avait pas.
    """
    sb = _get_supabase()
    if not sb:
        logger.warning("‚ö†Ô∏è [revoke_key] Client Supabase non disponible")
        return False
    try:
        res = (
            sb.table("api_keys")
            .update({
                "is_active": False,
                "revoked_at": datetime.datetime.now(ZoneInfo("UTC")).isoformat(),
                "revoked_reason": "replaced_by_user",
            })
            .eq("discord_user_id", discord_user_id)
            .eq("is_active", True)
            .execute()
        )
        revoked = bool(res.data)
        if revoked:
            logger.info(f"üîë [revoke_key] Cl√© r√©voqu√©e pour discord_user_id={discord_user_id}")
        else:
            logger.info(f"‚ÑπÔ∏è [revoke_key] Aucune cl√© active trouv√©e pour discord_user_id={discord_user_id}")
        return revoked
    except Exception as e:
        logger.error(f"‚ùå [revoke_key] Erreur pour discord_user_id={discord_user_id}: {e}")
        return False


def _insert_new_key_sync(discord_user_id: str, discord_name: str, key_hash: str) -> bool:
    """Ins√®re la nouvelle cl√© hach√©e dans Supabase (sync, via run_in_executor)."""
    sb = _get_supabase()
    if not sb:
        logger.warning("‚ö†Ô∏è [insert_key] Client Supabase non disponible")
        return False
    try:
        sb.table("api_keys").insert({
            "discord_user_id": discord_user_id,
            "discord_name": discord_name,
            "key_hash": key_hash,
            "is_active": True,
        }).execute()
        logger.info(f"‚úÖ [insert_key] Nouvelle cl√© ins√©r√©e pour {discord_name} (discord_user_id={discord_user_id})")
        return True
    except Exception as e:
        logger.error(f"‚ùå [insert_key] Erreur pour discord_user_id={discord_user_id}: {e}")
        return False


@bot.tree.command(name="generer-cle", description="G√©n√®re votre cl√© API personnelle pour publier des traductions")
async def generer_cle(interaction: discord.Interaction):
    """
    G√©n√®re (ou renouvelle) la cl√© API personnelle d'un traducteur.
    - R√©serv√© aux membres ayant le r√¥le TRANSLATOR_ROLE_ID.
    - L'ancienne cl√© est r√©voqu√©e imm√©diatement.
    - La nouvelle cl√© est envoy√©e en MP uniquement (jamais affich√©e dans un salon).
    """
    await interaction.response.defer(ephemeral=True)

    user_tag = f"{interaction.user} (id={interaction.user.id})"
    logger.info(f"üîë [generer-cle] Demande re√ßue de {user_tag}")

    # ‚îÄ‚îÄ 1. V√©rification du r√¥le (Correctif fetch_member int√©gr√©) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if not TRANSLATOR_ROLE_ID:
        logger.error("‚ùå [generer-cle] TRANSLATOR_ROLE_ID non configur√©")
        await interaction.followup.send(
            "‚ùå Le bot n'est pas configur√© (TRANSLATOR_ROLE_ID manquant). Contactez un administrateur.",
            ephemeral=True
        )
        return

    # On s'assure d'abord qu'on est sur un serveur
    if not interaction.guild:
        logger.warning(f"‚ö†Ô∏è [generer-cle] Commande hors serveur par {user_tag}")
        await interaction.followup.send(
            "‚ùå Cette commande doit √™tre utilis√©e depuis un salon sur le serveur.",
            ephemeral=True
        )
        return

    # CORRECTIF : On tente de r√©cup√©rer le membre de mani√®re asynchrone (API Discord)
    # plut√¥t que de se fier uniquement au cache local du bot.
    try:
        member = await interaction.guild.fetch_member(interaction.user.id)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è [generer-cle] Impossible de fetch_member pour {user_tag}: {e}")
        member = None

    if not member:
        logger.warning(f"‚ö†Ô∏è [generer-cle] Membre introuvable pour {user_tag}")
        await interaction.followup.send(
            "‚ùå Impossible de v√©rifier vos r√¥les. Assurez-vous d'√™tre bien membre du serveur.",
            ephemeral=True
        )
        return

    # V√©rification si l'utilisateur a le r√¥le OU est le propri√©taire du serveur
    has_role = any(r.id == TRANSLATOR_ROLE_ID for r in member.roles)
    is_owner = member.id == interaction.guild.owner_id

    if not (has_role or is_owner):
        logger.warning(f"‚õî [generer-cle] Acc√®s refus√© pour {user_tag}")
        await interaction.followup.send(
            "‚õî Vous n'avez pas le r√¥le requis pour g√©n√©rer une cl√© API.",
            ephemeral=True
        )
        return

    discord_user_id = str(interaction.user.id)
    discord_name = interaction.user.display_name
    loop = asyncio.get_event_loop()

    # ‚îÄ‚îÄ 2. R√©vocation de l'ancienne cl√© (si elle existe) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    had_existing = await loop.run_in_executor(None, _revoke_existing_key_sync, discord_user_id)
    _api_key_cache.evict_user(discord_user_id)

    # ‚îÄ‚îÄ 3. G√©n√©ration de la nouvelle cl√© ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    raw_key = _generate_raw_key()
    key_hash = _hash_raw_key(raw_key)
    logger.info(f"üîê [generer-cle] G√©n√©ration cl√© pour {discord_name} (renouvellement={had_existing})")

    ok = await loop.run_in_executor(None, _insert_new_key_sync, discord_user_id, discord_name, key_hash)
    if not ok:
        await interaction.followup.send(
            "‚ùå Erreur lors de la g√©n√©ration de votre cl√©. R√©essayez dans quelques instants.",
            ephemeral=True
        )
        return

    # ‚îÄ‚îÄ 4. Envoi en MP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    mp_sent = False
    try:
        dm_channel = await interaction.user.create_dm()
        await dm_channel.send(
            f"üîë **Votre cl√© API personnelle**\n\n"
            f"```\n{raw_key}\n```\n"
            f"**Comment l'utiliser :**\n"
            f"Dans l'application ‚Üí ‚öôÔ∏è Configuration ‚Üí Pr√©f√©rences ‚Üí **Cl√© d'acc√®s √† l'API**\n\n"
            f"‚ö†Ô∏è **Gardez cette cl√© secr√®te.** Ne la partagez jamais.\n"
            f"Si elle est compromise, relancez `/generer-cle` pour en obtenir une nouvelle "
            f"(l'ancienne sera automatiquement r√©voqu√©e).\n\n"
            f"{'üîÑ *Votre ancienne cl√© a √©t√© r√©voqu√©e.*' if had_existing else ''}"
        )
        mp_sent = True
        logger.info(f"üì® [generer-cle] Cl√© envoy√©e en MP √† {user_tag}")
    except discord.Forbidden:
        logger.warning(f"‚ö†Ô∏è [generer-cle] MP ferm√©s pour {user_tag}, fallback √©ph√©m√®re")
        mp_sent = False

    # ‚îÄ‚îÄ 5. R√©ponse dans le salon (√©ph√©m√®re) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if mp_sent:
        msg = (
            f"‚úÖ **Cl√© API {'renouvel√©e' if had_existing else 'g√©n√©r√©e'} avec succ√®s !**\n"
            f"Je vous l'ai envoy√©e en message priv√©.\n\n"
            f"{'üîÑ Votre ancienne cl√© a √©t√© r√©voqu√©e imm√©diatement.' if had_existing else ''}"
        )
    else:
        msg = (
            f"‚úÖ **Cl√© API {'renouvel√©e' if had_existing else 'g√©n√©r√©e'} !**\n"
            f"*(Impossible d'envoyer un MP ‚Äî activez vos messages priv√©s pour plus de s√©curit√©)*\n\n"
            f"```\n{raw_key}\n```\n"
            f"‚ö†Ô∏è Copiez cette cl√© maintenant, elle ne sera plus affich√©e.\n"
            f"{'üîÑ Votre ancienne cl√© a √©t√© r√©voqu√©e.' if had_existing else ''}"
        )

    await interaction.followup.send(msg, ephemeral=True)


@bot.tree.command(name="check_versions", description="Contr√¥le les versions F95 (salon my)")
async def check_versions(interaction: discord.Interaction):
    """Lance le contr√¥le des versions sur le salon my."""
    try:
        await interaction.response.defer(ephemeral=True)
    except Exception:
        pass

    # MODIFICATION ICI : ajout de await
    if not await _user_can_run_checks(interaction):
        logger.warning(f"‚õî [check_versions] Permission refus√©e pour {interaction.user} (id={interaction.user.id})")
        await interaction.followup.send("‚õî Permission insuffisante. Cette commande est r√©serv√©e aux Traducteurs.", ephemeral=True)
        return

    logger.info(f"üîç [check_versions] Lancement manuel par {interaction.user} (id={interaction.user.id})")
    try:
        await interaction.followup.send("‚è≥ Contr√¥le des versions F95 en cours‚Ä¶", ephemeral=True)
    except Exception:
        pass
    try:
        await run_version_check_once()
        logger.info(f"‚úÖ [check_versions] Contr√¥le termin√© (lanc√© par {interaction.user})")
        await interaction.followup.send("‚úÖ Contr√¥le termin√©.", ephemeral=True)
    except Exception as e:
        logger.error(f"‚ùå [check_versions] Erreur: {e}")
        await interaction.followup.send(f"‚ùå Erreur: {e}", ephemeral=True)


@bot.tree.command(name="cleanup_empty_messages", description="Supprime les messages vides dans les threads (sauf m√©tadonn√©es)")
async def cleanup_empty_messages_cmd(interaction: discord.Interaction):
    """Lance le nettoyage des messages vides manuellement."""
    try:
        await interaction.response.defer(ephemeral=True)
    except Exception:
        pass

    # MODIFICATION ICI : ajout de await
    if not await _user_can_run_checks(interaction):
        logger.warning(f"‚õî [cleanup] Permission refus√©e pour {interaction.user} (id={interaction.user.id})")
        await interaction.followup.send("‚õî Permission insuffisante. Cette commande est r√©serv√©e aux Traducteurs.", ephemeral=True)
        return

    logger.info(f"üßπ [cleanup] Lancement manuel par {interaction.user} (id={interaction.user.id})")
    try:
        await interaction.followup.send("‚è≥ Nettoyage des messages vides en cours‚Ä¶", ephemeral=True)
    except Exception:
        pass
    try:
        await run_cleanup_empty_messages_once()
        logger.info(f"‚úÖ [cleanup] Nettoyage termin√© (lanc√© par {interaction.user})")
        await interaction.followup.send("‚úÖ Nettoyage termin√©.", ephemeral=True)
    except Exception as e:
        logger.error(f"‚ùå [cleanup] Erreur: {e}")
        await interaction.followup.send(f"‚ùå Erreur: {e}", ephemeral=True)


@bot.tree.command(name="check_help", description="Affiche la liste des commandes et leur utilit√©")
async def check_help(interaction: discord.Interaction):
    """Affiche l'aide personnalis√©e."""
    try:
        await interaction.response.defer(ephemeral=True)
    except Exception:
        pass

    # MODIFICATION ICI : ajout de await
    if not await _user_can_run_checks(interaction):
        logger.warning(f"‚õî [check_help] Permission refus√©e pour {interaction.user} (id={interaction.user.id})")
        await interaction.followup.send("‚õî Permission insuffisante.", ephemeral=True)
        return

    logger.info(f"‚ÑπÔ∏è [check_help] Consult√© par {interaction.user} (id={interaction.user.id})")
    help_text = (
        "**üß∞ Commandes disponibles (Bot Publisher)**\n\n"
        "**üîë Cl√© API personnelle**\n"
        "**/generer-cle** ‚Äî G√©n√®re ou renouvelle votre cl√© API personnelle.\n"
        "R√©serv√© aux membres ayant le r√¥le Traducteur. La cl√© est envoy√©e en MP.\n"
        "√Ä entrer dans l'application ‚Üí ‚öôÔ∏è Configuration ‚Üí Pr√©f√©rences ‚Üí **Cl√© d'acc√®s √† l'API**.\n"
        "L'ancienne cl√© est automatiquement r√©voqu√©e √† chaque renouvellement.\n\n"
        "**üîç Contr√¥le des versions**\n"
        "**/check_versions** ‚Äî Lance manuellement le contr√¥le des versions F95 sur le forum.\n\n"
        "**üßπ Nettoyage**\n"
        "**/cleanup_empty_messages** ‚Äî Supprime les messages vides dans les threads (sauf m√©tadonn√©es).\n\n"
        "**‚ÑπÔ∏è T√¢ches automatiques**\n"
        f"‚Ä¢ Contr√¥le des versions : tous les jours √† {config.VERSION_CHECK_HOUR:02d}:{config.VERSION_CHECK_MINUTE:02d} (Europe/Paris)\n"
        f"‚Ä¢ Nettoyage des messages vides : tous les jours √† {config.CLEANUP_EMPTY_MESSAGES_HOUR:02d}:{config.CLEANUP_EMPTY_MESSAGES_MINUTE:02d} (Europe/Paris)\n"
        "‚Ä¢ Syst√®me anti-doublon actif (30 jours)\n\n"
        "**‚ÑπÔ∏è Acc√®s**\n"
        "Toutes les commandes sont r√©serv√©es aux membres ayant le r√¥le Traducteur."
    )
    await interaction.followup.send(help_text, ephemeral=True)


# ==================== √âV√âNEMENTS BOT ====================
@bot.event
async def on_ready():
    logger.info(f'ü§ñ Bot Publisher pr√™t : {bot.user} (id={bot.user.id})')
    try:
        synced = await bot.tree.sync()
        logger.info(f"‚úÖ {len(synced)} commande(s) slash synchronis√©e(s) : {[c.name for c in synced]}")
    except Exception as e:
        logger.error(f"‚ùå Sync commandes slash √©chou√©e: {e}")
    if not daily_version_check.is_running():
        daily_version_check.start()
        logger.info(f"‚úÖ Contr√¥le quotidien programm√© √† {config.VERSION_CHECK_HOUR:02d}:{config.VERSION_CHECK_MINUTE:02d} Europe/Paris")
    if not daily_cleanup_empty_messages.is_running():
        daily_cleanup_empty_messages.start()
        logger.info(f"‚úÖ Nettoyage messages vides programm√© √† {config.CLEANUP_EMPTY_MESSAGES_HOUR:02d}:{config.CLEANUP_EMPTY_MESSAGES_MINUTE:02d} Europe/Paris")
    if not sync_jeux_task.is_running():
            sync_jeux_task.start()
            logger.info("‚úÖ Synchronisation jeux planifi√©e (toutes les 2h)")        

# ==================== HELPERS API REST ====================
def _build_metadata_embed(metadata_b64: str) -> dict:
    """
    Embed "invisible" qui transporte metadata_b64 en respectant les limites Discord.
    - field.value: max ~1024 caract√®res -> on d√©coupe en chunks
    - max 25 fields
    """
    CHUNK_SIZE = 950
    chunks = [metadata_b64[i:i + CHUNK_SIZE] for i in range(0, len(metadata_b64), CHUNK_SIZE)]
    if len(chunks) > 25:
        chunks = chunks[:25]

    return {
        "color": 2829617,  # #2b2d31 (quasi invisible en dark mode)
        "footer": {"text": f"metadata:v1:chunks={len(chunks)}"},
        "fields": [
            {"name": "\u200b", "value": c, "inline": False}
            for c in chunks
        ]
    }

def _auth_headers():
    return {"Authorization": f"Bot {config.PUBLISHER_DISCORD_TOKEN}"}

async def _discord_request(session, method, path, headers=None, json_data=None, data=None):
    url = f"{config.DISCORD_API_BASE}{path}"
    try:
        async with session.request(method, url, headers=headers, json=json_data, data=data) as resp:
            rate_limiter.update_from_headers(resp.headers)
            try:
                data = await resp.json()
            except:
                data = await resp.text()
            return resp.status, data, resp.headers
    except Exception as e:
        logger.error(f"Erreur requ√™te Discord: {e}")
        return 500, {"error": str(e)}, {}

async def _discord_get(session, path):
    status, data, _ = await _discord_request(session, "GET", path, headers=_auth_headers())
    return status, data

async def _discord_list_messages(session, channel_id: str, limit: int = 50):
    """Liste les derniers messages d'un channel/thread (REST)."""
    status, data, _ = await _discord_request(
        session,
        "GET",
        f"/channels/{channel_id}/messages?limit={limit}",
        headers=_auth_headers()
    )
    if status >= 300 or not isinstance(data, list):
        return []
    return data

async def _discord_patch_json(session, path, payload):
    status, data, _ = await _discord_request(
        session, "PATCH", path,
        headers={**_auth_headers(), "Content-Type": "application/json"},
        json_data=payload
    )
    return status, data

async def _fetch_image_from_url(session, url: str) -> Optional[Tuple[bytes, str, str]]:
    """
    T√©l√©charge une image depuis une URL. Retourne (bytes, filename, content_type) ou None en cas d'√©chec.
    """
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as resp:
            if resp.status >= 400:
                logger.warning(f"‚ö†Ô∏è √âchec t√©l√©chargement image (status {resp.status}): {url[:60]}...")
                return None
            data = await resp.read()
            if not data:
                return None
            # Nom de fichier : depuis Content-Disposition ou extrait de l'URL
            disp = resp.headers.get("Content-Disposition")
            filename = "image.png"
            if disp and "filename=" in disp:
                part = disp.split("filename=")[-1].strip().strip('"\'')
                if part:
                    filename = part
            else:
                path = url.split("?")[0].strip("/")
                if "/" in path:
                    name = path.split("/")[-1]
                    if "." in name and len(name) < 200:
                        filename = name
            if not any(filename.lower().endswith(ext) for ext in (".png", ".jpg", ".jpeg", ".gif", ".webp")):
                filename = filename + ".png" if "." not in filename else "image.png"
            ctype = resp.headers.get("Content-Type") or "image/png"
            if ";" in ctype:
                ctype = ctype.split(";")[0].strip()
            return (data, filename, ctype)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Exception t√©l√©chargement image: {e}")
        return None

async def _discord_post_thread_with_attachment(
    session, forum_id: str, name: str, message_content: str,
    applied_tag_ids: Optional[List[str]], file_bytes: bytes, filename: str, content_type: str
):
    """
    Cr√©e un thread avec un message contenant une pi√®ce jointe (multipart/form-data).
    Retourne (status, data, headers).
    """
    payload = {
        "name": name,
        "message": {"content": message_content or " "}
    }
    if applied_tag_ids:
        payload["applied_tags"] = applied_tag_ids
    form = aiohttp.FormData()
    form.add_field("payload_json", json.dumps(payload), content_type="application/json")
    form.add_field("files[0]", file_bytes, filename=filename, content_type=content_type)
    return await _discord_request(
        session, "POST", f"/channels/{forum_id}/threads",
        headers=_auth_headers(), data=form
    )

async def _discord_patch_message_with_attachment(
    session, thread_id: str, message_id: str, content: str,
    file_bytes: bytes, filename: str, content_type: str
):
    """
    Met √† jour un message en rempla√ßant la pi√®ce jointe (multipart/form-data).
    payload_json.attachments avec id 0 et filename permet de remplacer l'attachment.
    """
    payload = {
        "content": content or " ",
        "embeds": [],
        "attachments": [{"id": 0, "filename": filename}]
    }
    form = aiohttp.FormData()
    form.add_field("payload_json", json.dumps(payload), content_type="application/json")
    form.add_field("files[0]", file_bytes, filename=filename, content_type=content_type)
    status, data, headers = await _discord_request(
        session, "PATCH", f"/channels/{thread_id}/messages/{message_id}",
        headers=_auth_headers(), data=form
    )
    return status, data

async def _discord_post_json(session, path, payload):
    """Envoie une requ√™te POST avec JSON et retourne les 3 valeurs attendues"""
    status, data, headers = await _discord_request(session, "POST", path, headers=_auth_headers(), json_data=payload)
    return status, data, headers

async def _discord_delete_message(session, channel_id: str, message_id: str):
    """Supprime un message Discord"""
    status, data, _ = await _discord_request(
        session, "DELETE", f"/channels/{channel_id}/messages/{message_id}", headers=_auth_headers()
    )
    return status < 300


async def _discord_delete_channel(session, channel_id: str) -> Tuple[bool, int]:
    """Supprime un channel/thread Discord (DELETE /channels/{channel_id}). Retourne (succ√®s, status_code)."""
    status, data, _ = await _discord_request(
        session, "DELETE", f"/channels/{channel_id}", headers=_auth_headers()
    )
    return (status < 300, status)


async def _delete_old_metadata_messages(session, thread_id: str, keep_message_id: str = None):
    """
    Supprime tous les anciens messages de m√©tadonn√©es dans un thread.
    Garde uniquement le message sp√©cifi√© (si fourni) ou le plus r√©cent.
    
    Args:
        session: Session aiohttp
        thread_id: ID du thread
        keep_message_id: ID du message √† garder (optionnel)
    
    Returns:
        Nombre de messages supprim√©s
    """
    try:
        messages = await _discord_list_messages(session, thread_id, limit=50)
        metadata_messages = []
        
        # Trouver tous les messages de m√©tadonn√©es
        for m in messages:
            msg_id = m.get("id")
            if not msg_id:
                continue
            
            # Ignorer le message √† garder
            if keep_message_id and msg_id == keep_message_id:
                continue
            
            # V√©rifier si c'est un message de m√©tadonn√©es
            for e in (m.get("embeds") or []):
                footer = (e.get("footer") or {}).get("text") or ""
                if footer.startswith("metadata:v1:") or footer.startswith("metadata:"):
                    metadata_messages.append(msg_id)
                    break
        
        # Supprimer tous les anciens messages de m√©tadonn√©es
        deleted_count = 0
        for msg_id in metadata_messages:
            if await _discord_delete_message(session, thread_id, msg_id):
                deleted_count += 1
                logger.info(f"üóëÔ∏è Message metadata supprim√©: {msg_id}")
            else:
                logger.warning(f"‚ö†Ô∏è √âchec suppression message metadata: {msg_id}")
        
        if deleted_count > 0:
            logger.info(f"‚úÖ {deleted_count} ancien(s) message(s) metadata supprim√©(s)")
        
        return deleted_count
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Exception suppression anciens messages metadata: {e}")
        return 0

def _message_has_metadata_embed(msg_dict: dict) -> bool:
    """Indique si le message contient un embed de m√©tadonn√©es (footer metadata:v1:)."""
    for e in (msg_dict.get("embeds") or []):
        footer = (e.get("footer") or {}).get("text") or ""
        if footer.startswith("metadata:v1:") or footer.startswith("metadata:"):
            return True
    return False

# Type de message Discord : changement de nom du channel/thread ("X a chang√© le titre du post : ‚Ä¶")
CHANNEL_NAME_CHANGE_TYPE = 4


def _is_message_empty_and_not_metadata(msg_dict: dict) -> bool:
    """
    True si le message est totalement vide : pas de contenu, pas de pi√®ce jointe, pas d'embed.
    On ne supprime jamais les messages contenant les m√©tadonn√©es ni ceux avec un embed (image, etc.).
    """
    content = (msg_dict.get("content") or "").strip()
    if content:
        return False
    attachments = msg_dict.get("attachments") or []
    if attachments:
        return False
    embeds = msg_dict.get("embeds") or []
    if not embeds:
        return True
    if _message_has_metadata_embed(msg_dict):
        return False
    return False


def _is_message_thread_name_change(msg_dict: dict) -> bool:
    """
    True si le message est une notification "X a chang√© le titre du post" (type CHANNEL_NAME_CHANGE ou contenu similaire).
    Ces messages ne sont pas utiles et peuvent √™tre supprim√©s par le nettoyage.
    """
    if msg_dict.get("type") == CHANNEL_NAME_CHANGE_TYPE:
        return True
    content = (msg_dict.get("content") or "").strip()
    if not content:
        return False
    # Secours : message bot avec texte "a chang√© le titre" / "changed the thread name"
    lower = content.lower()
    if "a chang√© le titre" in lower or "changed the thread name" in lower or "changed the channel name" in lower:
        return True
    return False


async def _clean_empty_messages_in_thread(session, thread_id: str) -> int:
    """
    Supprime dans un thread :
    - les messages vides (pas de contenu, pi√®ce jointe ni embed utile) ;
    - les messages "X a chang√© le titre du post" (type CHANNEL_NAME_CHANGE ou contenu similaire).
    Sauf le message de d√©part et les messages contenant les m√©tadonn√©es.
    L'API renvoie les messages du plus r√©cent au plus ancien ; le dernier de la liste est le message de d√©part.
    Returns:
        Nombre de messages supprim√©s
    """
    try:
        messages = await _discord_list_messages(session, thread_id, limit=50)
        if len(messages) <= 1:
            return 0
        # Ne jamais supprimer le message de d√©part (le plus ancien = dernier de la liste)
        starter_id = messages[-1].get("id") if messages else None
        to_delete = []
        for m in messages[:-1]:
            msg_id = m.get("id")
            if not msg_id or msg_id == starter_id:
                continue
            if _is_message_empty_and_not_metadata(m) or _is_message_thread_name_change(m):
                to_delete.append(msg_id)
        deleted = 0
        for msg_id in to_delete:
            # D√©lai entre chaque suppression (0.5-1 seconde)
            if deleted > 0:
                await asyncio.sleep(0.5 + random.random() * 0.5)
            
            if await _discord_delete_message(session, thread_id, msg_id):
                deleted += 1
                logger.info(f"üóëÔ∏è Message vide ou ¬´ titre chang√© ¬ª supprim√©: {msg_id} (thread {thread_id})")
            else:
                logger.warning(f"‚ö†Ô∏è √âchec suppression message: {msg_id}")
        return deleted
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Exception nettoyage messages vides (thread {thread_id}): {e}")
        return 0

async def _discord_suppress_embeds(session, channel_id: str, message_id: str) -> bool:
    try:
        status, msg = await _discord_get(session, f"/channels/{channel_id}/messages/{message_id}")
        if status >= 300:
            logger.warning(f"‚ö†Ô∏è Impossible de lire le message avant SUPPRESS_EMBEDS (status={status}): {msg}")
            return False

        new_flags = (msg.get("flags", 0) | 4)

        status, data = await _discord_patch_json(
            session,
            f"/channels/{channel_id}/messages/{message_id}",
            {"flags": new_flags}
        )
        if status >= 300:
            logger.warning(f"‚ö†Ô∏è Impossible de SUPPRESS_EMBEDS (status={status}): {data}")
            return False

        return True
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Exception SUPPRESS_EMBEDS: {e}")
        return False

async def _resolve_applied_tag_ids(session, forum_id, tags_raw):
    wanted = [t.strip() for t in (tags_raw or "").replace(';', ',').replace('|', ',').split(',') if t.strip()]
    if not wanted: return []
    status, ch = await _discord_get(session, f"/channels/{forum_id}")
    if status >= 300: return []
    available = ch.get("available_tags", [])
    applied = []
    for w in wanted:
        if w.isdigit():
            applied.append(int(w))
        else:
            for t in available:
                if t.get("name", "").lower() == w.lower():
                    applied.append(int(t["id"]))
                    break
    return list(dict.fromkeys(applied))

def _strip_image_url_from_content(content: str, image_url: str) -> str:
    """Retire l'URL d'image du contenu (lien et retours √† la ligne autour)."""
    final_content = content or " "
    final_content = re.sub(r'\n\s*' + re.escape(image_url) + r'\s*\n?', '\n', final_content)
    final_content = re.sub(r'\n\s*' + re.escape(image_url) + r'\s*$', '', final_content)
    final_content = re.sub(re.escape(image_url), '', final_content)
    final_content = re.sub(r'\n\n\n+', '\n\n', final_content)
    return final_content.strip()


async def _create_forum_post(session, forum_id, title, content, tags_raw, images, metadata_b64=None):
    """
    Cr√©e un post de forum Discord.
    - L'image est envoy√©e en pi√®ce jointe (fichier joint) sur le 1er message (t√©l√©charg√©e depuis l'URL).
    - Les m√©tadonn√©es sont stock√©es dans un 2e message (embed) puis SUPPRESS_EMBEDS sur ce 2e message.
    """
    applied_tag_ids = await _resolve_applied_tag_ids(session, forum_id, tags_raw)

    # D√©tecter une URL d'image dans le contenu (y compris query string compl√®te)
    image_exts = r"(?:jpg|jpeg|png|gif|webp|avif|bmp|svg|ico|tiff|tif)"
    image_url_pattern = re.compile(
        rf"https?://[^\s<>\"']+\.{image_exts}(?:\?[^\s<>\"']*)?",
        re.IGNORECASE
    )
    image_urls_full = [m.group(0) for m in image_url_pattern.finditer(content or "")]

    final_content = content or " "
    use_attachment = False
    file_bytes, filename, content_type = None, "image.png", "image/png"

    if image_urls_full:
        image_url = image_urls_full[0]
        # T√©l√©charger l'image et l'envoyer en pi√®ce jointe (au lieu d'embed)
        fetched = await _fetch_image_from_url(session, image_url)
        if fetched:
            file_bytes, filename, content_type = fetched
            final_content = _strip_image_url_from_content(content or " ", image_url)
            use_attachment = True
            logger.info(f"‚úÖ Image en pi√®ce jointe (message principal): {image_url[:60]}...")
        else:
            # Fallback : embed si le t√©l√©chargement √©choue
            final_content = _strip_image_url_from_content(content or " ", image_url)
            logger.info(f"‚ö†Ô∏è T√©l√©chargement image √©chou√©, fallback embed: {image_url[:60]}...")

    if use_attachment and file_bytes:
        status, data, _ = await _discord_post_thread_with_attachment(
            session, forum_id, title, final_content or " ", applied_tag_ids,
            file_bytes, filename, content_type
        )
    else:
        # Sans image ou fallback embed
        message_embeds = []
        if image_urls_full and not use_attachment:
            message_embeds.append({"image": {"url": image_urls_full[0]}})
        message_payload = {"content": final_content or " ", "embeds": message_embeds}
        payload = {"name": title, "message": message_payload}
        if applied_tag_ids:
            payload["applied_tags"] = applied_tag_ids
        status, data, _ = await _discord_post_json(session, f"/channels/{forum_id}/threads", payload)

    if status >= 300:
        return False, {"status": status, "discord": data}

    thread_id = data.get("id")
    # Discord peut renvoyer le message starter dans "message" ou last_message_id (channel object)
    message_id = (data.get("message") or {}).get("id") or data.get("message_id") or data.get("last_message_id")
    if not message_id and thread_id:
        # Fallback : r√©cup√©rer l'id du message de d√©part en listant les messages du thread
        try:
            messages = await _discord_list_messages(session, str(thread_id), limit=5)
            if messages:
                # Les messages sont du plus r√©cent au plus ancien ; le dernier est le message de d√©part
                message_id = (messages[-1] or {}).get("id")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible de r√©cup√©rer le message de d√©part (thread {thread_id}): {e}")
    # Garantir des cha√Ænes pour le frontend (suppression, historique)
    thread_id = str(thread_id) if thread_id is not None else None
    message_id = str(message_id) if message_id is not None else None

    # Publier les m√©tadonn√©es dans un 2e message puis SUPPRESS_EMBEDS sur ce 2e message
    # Structure: Message 1 = contenu + image, Message 2 = m√©tadonn√©es
    if metadata_b64 and thread_id:
        try:
            if len(metadata_b64) > 25000:
                logger.warning("‚ö†Ô∏è metadata_b64 trop long, metadata message ignor√© pour √©viter un 400 Discord")
            else:
                # Supprimer tous les anciens messages de m√©tadonn√©es avant d'en cr√©er un nouveau
                await _delete_old_metadata_messages(session, str(thread_id))
                
                meta_payload = {
                    "content": " ",
                    "embeds": [_build_metadata_embed(metadata_b64)]
                }
                s2, d2, _ = await _discord_post_json(session, f"/channels/{thread_id}/messages", meta_payload)
                if s2 < 300 and isinstance(d2, dict) and d2.get("id"):
                    await _discord_suppress_embeds(session, str(thread_id), str(d2["id"]))
                else:
                    logger.warning(f"‚ö†Ô∏è √âchec cr√©ation message metadata (status={s2}): {d2}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Exception cr√©ation/suppression metadata message: {e}")

    return True, {
        "thread_id": thread_id,
        "message_id": message_id,
        "guild_id": data.get("guild_id"),
        "thread_url": f"https://discord.com/channels/{data.get('guild_id')}/{thread_id}"
    }

def _get_client_ip(request) -> str:
    """Extrait l'IP du client en tenant compte des reverse proxies."""
    forwarded = request.headers.get("X-Forwarded-For")
    if forwarded:
        return forwarded.split(",")[0].strip()
    real_ip = request.headers.get("X-Real-IP")
    if real_ip:
        return real_ip.strip()
    return request.remote or "unknown"

def _get_user_id(request) -> str:
    """Extrait l'UUID utilisateur du header X-User-ID."""
    user_id = request.headers.get("X-User-ID", "").strip()
    return user_id if user_id else "NULL"

def _with_cors(request, resp):
    """Applique les headers CORS avec whitelist d'origines autoris√©es."""
    origin = request.headers.get("Origin", "")
    
    # Parse ALLOWED_ORIGINS (par d√©faut: tauri://localhost)
    allowed_raw = config.ALLOWED_ORIGINS or "tauri://localhost"
    allowed_origins = [o.strip() for o in allowed_raw.split(",") if o.strip()]
    
    # Autoriser si l'origine est dans la whitelist ou si elle commence par http://localhost ou http://127.0.0.1
    if origin in allowed_origins or origin.startswith("http://localhost") or origin.startswith("http://127.0.0.1") or origin.startswith("tauri://"):
        resp.headers.update({
            "Access-Control-Allow-Origin": origin,
            "Access-Control-Allow-Methods": "GET,POST,PATCH,OPTIONS",
            "Access-Control-Allow-Headers": "*",
            "Access-Control-Allow-Credentials": "true"
        })
    else:
        # Fallback pour compatibilit√© (peut √™tre retir√© en production stricte)
        resp.headers.update({
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET,POST,PATCH,OPTIONS",
            "Access-Control-Allow-Headers": "*"
        })
    
    return resp


async def _send_announcement(
    session,
    is_update: bool,
    title: str,
    thread_url: str,
    translator_label: str,
    state_label: str,
    game_version: str,
    translate_version: str,
    image_url: Optional[str] = None,
    forum_id: int = None,          # ‚Üê nouveau param√®tre
) -> bool:
    if not config.PUBLISHER_ANNOUNCE_CHANNEL_ID:
        logger.warning("‚ö†Ô∏è PUBLISHER_ANNOUNCE_CHANNEL_ID non configur√©, annonce non envoy√©e")
        return False

    title_clean = (title or "").strip() or "Sans titre"
    game_version = (game_version or "").strip() or "Non sp√©cifi√©e"
    translate_version = (translate_version or "").strip() or "Non sp√©cifi√©e"
    prefixe = "üîÑ **Mise √† jour d'une traduction**" if is_update else "üéÆ **Nouvelle traduction**"

    msg_content = f"{prefixe}\n\n"
    msg_content += f"**Nom du jeu :** [{title_clean}]({thread_url})\n"
    if translator_label and translator_label.strip():
        msg_content += f"**Traducteur :** {translator_label.strip()}\n"
    msg_content += f"**Version du jeu :** `{game_version}`\n"
    msg_content += f"**Version de la traduction :** `{translate_version}`\n"
    if state_label and state_label.strip():
        msg_content += f"\n**√âtat :** {state_label.strip()}\n"
    msg_content += "\n**Bon jeu √† vous** üòä"

    # ‚Üê forum_id transmis : pointe vers le bon salon
    forum_link = _build_forum_link(thread_url, forum_id=forum_id)
    if forum_link:
        msg_content += f"\n\n> üìö Retrouvez toutes mes traductions ‚Üí [Acc√©der au forum]({forum_link})"

    payload = {"content": msg_content}
    if image_url and image_url.strip().startswith("http"):
        payload["embeds"] = [{"color": 0x4ADE80, "image": {"url": image_url.strip()}}]

    status, data, _ = await _discord_post_json(
        session,
        f"/channels/{config.PUBLISHER_ANNOUNCE_CHANNEL_ID}/messages",
        payload,
    )
    if status >= 300:
        logger.warning(f"‚ö†Ô∏è √âchec envoi annonce (status={status}): {data}")
        return False

    logger.info(f"‚úÖ Annonce envoy√©e ({'mise √† jour' if is_update else 'nouvelle traduction'}): {title_clean}")
    return True


async def _send_deletion_announcement(
    session,
    title: str,
    reason: str = None,
    thread_url: str = None,
) -> bool:
    """
    Envoie une annonce de suppression de post dans PUBLISHER_ANNOUNCE_CHANNEL_ID.
    Format : titre du post supprim√©, raison si fournie.
    """
    if not config.PUBLISHER_ANNOUNCE_CHANNEL_ID:
        logger.warning("‚ö†Ô∏è PUBLISHER_ANNOUNCE_CHANNEL_ID non configur√©, annonce de suppression non envoy√©e")
        return False
    
    title_clean = (title or "").strip() or "Publication"
    reason_clean = (reason or "").strip()
    
    msg_content = "üóëÔ∏è **Suppression d'une publication**\n\n"
    msg_content += f"**Publication supprim√©e :** {title_clean}\n"
    
    if reason_clean:
        msg_content += f"**Raison :** {reason_clean}\n"
    
    forum_link = _build_forum_link(thread_url)
    if forum_link:
        msg_content += f"\n\n> üìö Retrouvez toutes mes traductions ‚Üí [Acc√©der au forum]({forum_link})"

    footer_text = "Cette publication a √©t√© retir√©e d√©finitivement"
    payload = {
        "content": msg_content,
        "embeds": [{
            "color": 0xFF6B6B,
            "footer": {"text": footer_text}
        }]
    }
    
    status, data, _ = await _discord_post_json(
        session,
        f"/channels/{config.PUBLISHER_ANNOUNCE_CHANNEL_ID}/messages",
        payload,
    )
    
    if status >= 300:
        logger.warning(f"‚ö†Ô∏è √âchec envoi annonce suppression (status={status}): {data}")
        return False
    
    logger.info(f"‚úÖ Annonce de suppression envoy√©e: {title_clean}")
    return True


# ==================== MIDDLEWARE ====================
# Cache pour stocker les UUID par IP (pour les requ√™tes OPTIONS sans UUID)
_ip_user_cache = {}

@web.middleware
async def logging_middleware(request, handler):
    client_ip = _get_client_ip(request)
    user_id = _get_user_id(request)
    method = request.method
    path = request.path

    # R√©cup√©rer la cl√© API (pour identifier les utilisateurs l√©gitimes)
    raw_key = (request.headers.get("X-API-KEY") or "").strip()
    # On loggue seulement les 8 premiers caract√®res (suffisant pour identifier, pas pour voler)
    key_hint = raw_key[:8] + "..." if len(raw_key) > 8 else ("NOKEY" if not raw_key else raw_key)

    # R√©soudre le cache UUID depuis l'IP pour les OPTIONS
    if not user_id or user_id == "NULL":
        if client_ip in _ip_user_cache:
            user_id = _ip_user_cache[client_ip]
    else:
        _ip_user_cache[client_ip] = user_id

    # Log enrichi ‚Äî format parsable par fail2ban
    logger.info(f"[REQUEST] {client_ip} | {user_id} | {key_hint} | {method} {path}")

    response = await handler(request)

    # Log des erreurs 4xx/5xx pour fail2ban
    if response.status >= 400:
        logger.warning(
            f"[HTTP_ERROR] {client_ip} | {user_id} | {key_hint} | "
            f"{method} {path} | STATUS={response.status}"
        )

    return response


# ‚îÄ‚îÄ Ajouter dans publisher_api.py ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

F95FR_API_URL = "https://f95fr.duckdns.org/api/jeux"
F95FR_API_KEY = os.getenv("F95FR_API_KEY", "NL7A1A7p9hPwY9Qf6dgV")

async def get_jeux(request):
    """
    Sert les jeux depuis le cache Supabase (f95_jeux).
    Fallback sur l'API externe si la table est vide ou inaccessible.
    Le bot se charge de rafra√Æchir toutes les 2h via sync_jeux_task.
    """
    is_valid, _, _, _ = await _auth_request(request, "/api/jeux")
    if not is_valid:
        return _with_cors(request, web.json_response(
            {"ok": False, "error": "Invalid API key"}, status=401
        ))

    sb = _get_supabase()

    # ‚îÄ‚îÄ Priorit√© : lire depuis le cache Supabase ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if sb:
        try:
            res = sb.table("f95_jeux").select("*").order("nom_du_jeu").execute()
            if res.data:
                logger.info(f"[get_jeux] {len(res.data)} jeux depuis Supabase (cache)")
                return _with_cors(request, web.json_response({
                    "ok": True, "jeux": res.data,
                    "count": len(res.data), "source": "cache"
                }))
        except Exception as e:
            logger.warning(f"[get_jeux] Supabase indisponible, fallback API externe: {e}")

    # ‚îÄ‚îÄ Fallback : API externe (table vide au premier d√©marrage) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(
                F95FR_API_URL,
                headers={"X-API-KEY": F95FR_API_KEY},
                timeout=aiohttp.ClientTimeout(total=30)
            ) as resp:
                if resp.status != 200:
                    logger.warning(f"[get_jeux] API f95fr error {resp.status}")
                    return _with_cors(request, web.json_response(
                        {"ok": False, "error": f"API upstream {resp.status}"}, status=502
                    ))
                data = await resp.json()

        # Peupler le cache en arri√®re-plan
        if sb and isinstance(data, list):
            loop = asyncio.get_event_loop()
            loop.run_in_executor(None, _sync_jeux_to_supabase, data)

        logger.info(f"[get_jeux] {len(data) if isinstance(data, list) else '?'} jeux depuis API externe (fallback)")
        return _with_cors(request, web.json_response({
            "ok": True, "jeux": data,
            "count": len(data), "source": "api"
        }))

    except Exception as e:
        logger.error(f"[get_jeux] Exception: {e}")
        return _with_cors(request, web.json_response(
            {"ok": False, "error": str(e)}, status=500
        ))


def _sync_jeux_to_supabase(jeux: list):
    """
    Upsert des jeux dans la table f95_jeux (sync arri√®re-plan).
    Pr√©serve le champ published_post_id s'il existe d√©j√†.
    """
    sb = _get_supabase()
    if not sb or not jeux:
        return
    try:
        now = datetime.datetime.now(ZoneInfo("UTC")).isoformat()
        rows = []
        for j in jeux:
            rows.append({
                "id":                 j.get("id"),
                "site_id":            j.get("site_id"),
                "site":               j.get("site"),
                "nom_du_jeu":         j.get("nom_du_jeu") or "",
                "nom_url":            j.get("nom_url"),
                "version":            j.get("version"),
                "trad_ver":           j.get("trad_ver"),
                "lien_trad":          j.get("lien_trad"),
                "statut":             j.get("statut"),
                "tags":               j.get("tags"),
                "type":               j.get("type"),
                "traducteur":         j.get("traducteur"),
                "traducteur_url":     j.get("traducteur_url"),
                "relecture":          j.get("relecture"),
                "type_de_traduction": j.get("type_de_traduction"),
                "ac":                 str(j.get("ac") or ""),
                "image":              j.get("image"),
                "type_maj":           j.get("type_maj"),
                "date_maj":           j.get("date_maj"),
                "synced_at":          now,
                "updated_at":         now,
            })
        # Upsert par lots de 50 (limite Supabase)
        for i in range(0, len(rows), 50):
            sb.table("f95_jeux").upsert(
                rows[i:i+50],
                on_conflict="id",
                # Ne pas √©craser published_post_id s'il existe
                ignore_duplicates=False
            ).execute()
        logger.info(f"[sync_jeux] {len(rows)} jeux synchronis√©s dans Supabase")
    except Exception as e:
        logger.warning(f"[sync_jeux] Erreur sync Supabase: {e}")


# ‚îÄ‚îÄ Ajouter la route dans make_app() ou dans la liste des routes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ("GET", "/api/jeux", get_jeux),

# ==================== HANDLERS HTTP ====================
async def health(request):
    return _with_cors(request, web.json_response({"ok": True, "configured": config.configured, "rate_limit": rate_limiter.get_info()}))

async def options_handler(request):
    return _with_cors(request, web.Response(status=204))

async def configure(request):
    """Handler pour configurer l'API (prot√©g√© par cl√© API)."""
    is_valid, _, _, _ = await _auth_request(request, "/api/configure")
    if not is_valid:
        return _with_cors(request, web.json_response({"ok": False, "error": "Invalid API key"}, status=401))
    
    try:
        data = await request.json()
        config.update_from_frontend(data)
        resp = web.json_response({"ok": True, "message": "Configuration mise √† jour", "configured": config.configured})
        return _with_cors(request, resp)
    except Exception as e:
        logger.error(f"[API] Erreur configuration: {e}")
        return _with_cors(request, web.json_response({"ok": False, "error": str(e)}, status=400))

async def forum_post(request):
    """Handler pour publier un post dans le salon my uniquement."""
    is_valid, discord_user_id, discord_name, is_legacy = await _auth_request(request, "/api/forum-post")
    if not is_valid:
        return _with_cors(request, web.json_response({"ok": False, "error": "Invalid API key"}, status=401))
    if not config.FORUM_MY_ID:
        return _with_cors(request, web.json_response({"ok": False, "error": "PUBLISHER_FORUM_TRAD_ID non configur√©"}, status=500))
    title, content, tags, metadata_b64 = "", "", "", None
    translator_label, state_label, game_version, received_forum_id, translate_version, announce_image_url = "", "", "", "", "", ""
    history_payload_raw = None
    reader = await request.multipart()
    async for part in reader:
        if part.name == "title":
            title = (await part.text()).strip()
        elif part.name == "content":
            content = (await part.text()).strip()
        elif part.name == "tags":
            tags = (await part.text()).strip()
        elif part.name == "metadata":
            metadata_b64 = (await part.text()).strip()
        elif part.name == "translator_label":
            translator_label = (await part.text()).strip()
        elif part.name == "state_label":
            state_label = (await part.text()).strip()
        elif part.name == "game_version":
            game_version = (await part.text()).strip()
        elif part.name == "translate_version":
            translate_version = (await part.text()).strip()
        elif part.name == "announce_image_url":
            announce_image_url = (await part.text()).strip()
        elif part.name == "forum_channel_id":
            received_forum_id = (await part.text()).strip()            
        elif part.name == "history_payload":
            history_payload_raw = (await part.text()).strip()
    forum_id = int(received_forum_id) if received_forum_id else config.FORUM_MY_ID

    async with aiohttp.ClientSession() as session:
        ok, result = await _create_forum_post(session, forum_id, title, content, tags, [], metadata_b64)
        if ok and config.PUBLISHER_ANNOUNCE_CHANNEL_ID:
            await _send_announcement(
                session,
                is_update=False,
                title=title,
                thread_url=result.get("thread_url", ""),
                translator_label=translator_label,
                state_label=state_label,
                game_version=game_version,
                translate_version=translate_version,
                image_url=announce_image_url or None,
                forum_id=forum_id,
            )
    if not ok:
        return _with_cors(request, web.json_response({"ok": False, "details": result}, status=500))

    if history_payload_raw:
        try:
            payload = json.loads(history_payload_raw)
            payload["thread_id"] = result.get("thread_id") or ""
            payload["message_id"] = result.get("message_id") or ""
            payload["discord_url"] = result.get("thread_url") or ""
            payload["forum_id"] = forum_id
            ts = int(time.time() * 1000)
            if "created_at" not in payload or not payload.get("created_at"):
                payload["created_at"] = datetime.datetime.now(ZoneInfo("UTC")).isoformat()
            payload["updated_at"] = datetime.datetime.now(ZoneInfo("UTC")).isoformat()
            if "timestamp" not in payload:
                payload["timestamp"] = ts
            sb = _get_supabase()
            if sb:
                try:
                    supabase_payload = {k: v for k, v in payload.items() if k not in ['timestamp', 'template']}
                    res = sb.table("published_posts").upsert(supabase_payload, on_conflict="id").execute()
                    logger.info(f"‚úÖ Post enregistr√© dans Supabase: {payload.get('title')}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è √âchec sauvegarde Supabase lors de la cr√©ation: {e}")
        except Exception as e:
            logger.warning(f"Historique (create): payload invalide, fallback minimal: {e}")
            fallback_payload = {
                "id": f"post_{int(time.time())}",
                "timestamp": int(time.time() * 1000),
                "title": title,
                "content": content,
                "tags": tags,
                "template": "my",
                "thread_id": result["thread_id"],
                "message_id": result["message_id"],
                "discord_url": result["thread_url"],
                "forum_id": forum_id,
            }
            sb = _get_supabase()
            if sb:
                try:
                    supabase_fallback = {k: v for k, v in fallback_payload.items() if k not in ['timestamp', 'template']}
                    supabase_fallback["created_at"] = datetime.datetime.now(ZoneInfo("UTC")).isoformat()
                    supabase_fallback["updated_at"] = datetime.datetime.now(ZoneInfo("UTC")).isoformat()
                    res = sb.table("published_posts").upsert(supabase_fallback, on_conflict="id").execute()
                    logger.info(f"‚úÖ Post (fallback) enregistr√© dans Supabase: {title}")
                except Exception as e2:
                    logger.warning(f"‚ö†Ô∏è √âchec sauvegarde Supabase fallback: {e2}")
    else:
        fallback_payload = {
            "id": f"post_{int(time.time())}",
            "timestamp": int(time.time() * 1000),
            "title": title,
            "content": content,
            "tags": tags,
            "template": "my",
            "thread_id": result["thread_id"],
            "message_id": result["message_id"],
            "discord_url": result["thread_url"],
            "forum_id": forum_id,
        }
        sb = _get_supabase()
        if sb:
            try:
                supabase_fallback = {k: v for k, v in fallback_payload.items() if k not in ['timestamp', 'template']}
                supabase_fallback["created_at"] = datetime.datetime.now(ZoneInfo("UTC")).isoformat()
                supabase_fallback["updated_at"] = datetime.datetime.now(ZoneInfo("UTC")).isoformat()
                res = sb.table("published_posts").upsert(supabase_fallback, on_conflict="id").execute()
                logger.info(f"‚úÖ Post (no payload) enregistr√© dans Supabase: {title}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec sauvegarde Supabase no payload: {e}")

    # ‚îÄ‚îÄ R√©ponse finale avec warning legacy si n√©cessaire ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    response_data = {"ok": True, **result}
    if is_legacy:
        response_data["legacy_key_warning"] = LEGACY_KEY_WARNING
    return _with_cors(request, web.json_response(response_data))

async def forum_post_update(request):
    """Handler pour mettre √† jour un post ‚Äî avec re-routage automatique si mauvais salon."""
    is_valid, discord_user_id, discord_name, is_legacy = await _auth_request(request, "/api/forum-post/update")
    if not is_valid:
        return _with_cors(request, web.json_response({"ok": False, "error": "Invalid API key"}, status=401))
    if not config.FORUM_MY_ID:
        return _with_cors(request, web.json_response({"ok": False, "error": "PUBLISHER_FORUM_TRAD_ID non configur√©"}, status=500))

    title, content, tags, thread_id, message_id, metadata_b64 = "", "", "", None, None, None
    translator_label, state_label, game_version, received_forum_id = "", "", "", ""
    translate_version, announce_image_url, thread_url = "", "", ""
    history_payload_raw = None
    silent_update = False

    reader = await request.multipart()
    async for part in reader:
        name = part.name
        if name == "silent_update":
            val = (await part.text()).strip().lower()
            silent_update = val in ("true", "1", "yes")
        elif name == "title":          title = (await part.text()).strip()
        elif name == "content":        content = (await part.text()).strip()
        elif name == "tags":           tags = (await part.text()).strip()
        elif name == "threadId":       thread_id = (await part.text()).strip()
        elif name == "messageId":      message_id = (await part.text()).strip()
        elif name == "metadata":       metadata_b64 = (await part.text()).strip()
        elif name == "translator_label":   translator_label = (await part.text()).strip()
        elif name == "state_label":        state_label = (await part.text()).strip()
        elif name == "game_version":       game_version = (await part.text()).strip()
        elif name == "translate_version":  translate_version = (await part.text()).strip()
        elif name == "announce_image_url": announce_image_url = (await part.text()).strip()
        elif name == "forum_channel_id":   received_forum_id = (await part.text()).strip()
        elif name == "thread_url":         thread_url = (await part.text()).strip()
        elif name == "history_payload":    history_payload_raw = (await part.text()).strip()

    if not thread_id or not message_id:
        return _with_cors(request, web.json_response({"ok": False, "error": "threadId and messageId required"}, status=400))

    target_forum_id = int(received_forum_id) if received_forum_id else config.FORUM_MY_ID
    reroute_info = None  # Contiendra les infos si re-routage effectu√©

    async with aiohttp.ClientSession() as session:

        # ‚îÄ‚îÄ D√âTECTION RE-ROUTAGE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        current_parent_id = await _get_thread_parent_id(session, thread_id)
        needs_reroute = (
            current_parent_id
            and received_forum_id
            and current_parent_id != received_forum_id
        )

        if needs_reroute:
            logger.info(
                f"üîÄ Re-routage d√©tect√©: thread {thread_id} est dans {current_parent_id}, "
                f"doit √™tre dans {received_forum_id}"
            )
            reroute_info = await _reroute_post(
                session,
                old_thread_id=thread_id,
                old_message_id=message_id,
                target_forum_id=received_forum_id,
                title=title,
                content=content,
                tags_raw=tags,
                metadata_b64=metadata_b64,
            )
            if reroute_info:
                # Mettre √† jour les IDs pour la suite (historique, Supabase, r√©ponse)
                old_thread_id_for_cleanup = thread_id
                thread_id = reroute_info["thread_id"]
                message_id = reroute_info["message_id"]
                thread_url = reroute_info["thread_url"]
                # Nettoyer l'entr√©e Supabase/historique de l'ancien thread
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(
                    None, _delete_from_supabase_sync, old_thread_id_for_cleanup, None
                )
            else:
                logger.error("‚ùå Re-routage √©chou√©, mise √† jour normale en fallback")
                # On retombe sur la mise √† jour classique sans re-routage
                needs_reroute = False

        # ‚îÄ‚îÄ MISE √Ä JOUR CLASSIQUE (si pas de re-routage ou re-routage √©chou√©) ‚îÄ
        if not needs_reroute:
            message_path = f"/channels/{thread_id}/messages/{message_id}"

            image_exts = r"(?:jpg|jpeg|png|gif|webp|avif|bmp|svg|ico|tiff|tif)"
            image_url_pattern = re.compile(
                rf"https?://[^\s<>\"']+\.{image_exts}(?:\?[^\s<>\"']*)?",
                re.IGNORECASE
            )
            image_urls_full = [m.group(0) for m in image_url_pattern.finditer(content or "")]

            final_content = content or " "
            use_attachment = False
            file_bytes, filename, content_type = None, "image.png", "image/png"

            if image_urls_full:
                image_url = image_urls_full[0]
                fetched = await _fetch_image_from_url(session, image_url)
                if fetched:
                    file_bytes, filename, content_type = fetched
                    final_content = _strip_image_url_from_content(content or " ", image_url)
                    use_attachment = True
                else:
                    final_content = _strip_image_url_from_content(content or " ", image_url)

            if use_attachment and file_bytes:
                status, data = await _discord_patch_message_with_attachment(
                    session, str(thread_id), str(message_id), final_content or " ",
                    file_bytes, filename, content_type
                )
            else:
                status, data = await _discord_patch_json(
                    session, message_path, {"content": final_content or " ", "embeds": []}
                )

            if status >= 300:
                return _with_cors(request, web.json_response({"ok": False, "details": data}, status=500))

            # Mise √† jour metadata
            if metadata_b64 and len(metadata_b64) <= 25000:
                try:
                    messages = await _discord_list_messages(session, str(thread_id), limit=50)
                    metadata_message_id = None
                    for m in messages:
                        for e in (m.get("embeds") or []):
                            footer = (e.get("footer") or {}).get("text") or ""
                            if footer.startswith("metadata:v1:") or footer.startswith("metadata:"):
                                metadata_message_id = m.get("id")
                                break
                        if metadata_message_id:
                            break

                    meta_payload = {"content": " ", "embeds": [_build_metadata_embed(metadata_b64)]}
                    if metadata_message_id:
                        s3, d3 = await _discord_patch_json(session, f"/channels/{thread_id}/messages/{metadata_message_id}", meta_payload)
                        if s3 < 300:
                            await _discord_suppress_embeds(session, str(thread_id), str(metadata_message_id))
                            await _delete_old_metadata_messages(session, str(thread_id), keep_message_id=str(metadata_message_id))
                    else:
                        await _delete_old_metadata_messages(session, str(thread_id))
                        s2, d2, _ = await _discord_post_json(session, f"/channels/{thread_id}/messages", meta_payload)
                        if s2 < 300 and isinstance(d2, dict) and d2.get("id"):
                            await _discord_suppress_embeds(session, str(thread_id), str(d2["id"]))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Exception update/cr√©ation metadata message: {e}")

            # Mise √† jour titre + tags du thread
            applied_tag_ids = await _resolve_applied_tag_ids(session, target_forum_id, tags)
            status, data = await _discord_patch_json(session, f"/channels/{thread_id}", {
                "name": title,
                "applied_tags": applied_tag_ids
            })
            if status >= 300:
                return _with_cors(request, web.json_response({"ok": False, "details": data}, status=500))

        # ‚îÄ‚îÄ ANNONCE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if config.PUBLISHER_ANNOUNCE_CHANNEL_ID and thread_url and not silent_update:
            await _send_announcement(
                session,
                is_update=True,
                title=title,
                thread_url=thread_url,
                translator_label=translator_label,
                state_label=state_label,
                game_version=game_version,
                translate_version=translate_version,
                image_url=announce_image_url or None,
                forum_id=target_forum_id,
            )        
        elif silent_update:
            logger.info(f"üîá Mise √† jour silencieuse (sans annonce): {title}")

        # ‚îÄ‚îÄ HISTORIQUE & SUPABASE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        ts = int(time.time() * 1000)
        loop = asyncio.get_event_loop()
        existing_row = await loop.run_in_executor(None, _fetch_post_by_thread_id_sync, thread_id)

        payload = {}
        if history_payload_raw:
            try:
                payload = json.loads(history_payload_raw)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Payload JSON invalide: {e}")

        final_payload = dict(existing_row) if existing_row else {}
        final_payload.update(payload)
        final_payload["thread_id"] = thread_id
        final_payload["message_id"] = message_id
        final_payload["discord_url"] = (thread_url or "").strip() or final_payload.get("discord_url") or ""
        final_payload["title"] = title
        final_payload["content"] = content
        final_payload["tags"] = tags
        final_payload["updated_at"] = datetime.datetime.now(ZoneInfo("UTC")).isoformat()
        if "created_at" not in final_payload or not final_payload.get("created_at"):
            final_payload["created_at"] = datetime.datetime.now(ZoneInfo("UTC")).isoformat()

        final_payload = _normalize_history_row(final_payload)

        sb = _get_supabase()
        if sb:
            try:
                supabase_payload = {k: v for k, v in final_payload.items() if k not in ['timestamp', 'template']}
                sb.table("published_posts").upsert(supabase_payload, on_conflict="id").execute()
                logger.info(f"‚úÖ Post {'re-rout√© et ' if reroute_info else ''}enregistr√© dans Supabase: {title}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec sauvegarde Supabase: {e}")

    # ‚îÄ‚îÄ R√âPONSE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    response_data = {
        "ok": True,
        "updated": True,
        "rerouted": bool(reroute_info),  # ‚Üê le frontend sait qu'un re-routage a eu lieu
        "thread_id": thread_id,
        "message_id": message_id,
        "thread_url": thread_url,
        "discord_url": thread_url,
        "forum_id": target_forum_id or 0,
        "threadId": thread_id,
        "messageId": message_id,
        "threadUrl": thread_url,
        "discordUrl": thread_url,
        "forumId": target_forum_id or 0,
    }
    if is_legacy:
        response_data["legacy_key_warning"] = LEGACY_KEY_WARNING
    return _with_cors(request, web.json_response(response_data))

async def get_history(request):
    is_valid, _, _, is_legacy = await _auth_request(request, "/api/history")
    if not is_valid:
        return _with_cors(request, web.json_response({"ok": False, "error": "Invalid API key"}, status=401))
    sb = _get_supabase()
    if not sb:
        return _with_cors(request, web.json_response({"ok": False, "error": "Supabase non configur√©"}, status=500))
    res = sb.table("published_posts").select("*").order("updated_at", desc=True).limit(1000).execute()
    posts = [_normalize_history_row(r) for r in (res.data or [])]
    response_data = {"ok": True, "posts": posts, "count": len(posts)}
    if is_legacy:
        response_data["legacy_key_warning"] = LEGACY_KEY_WARNING
    return _with_cors(request, web.json_response(response_data))


async def forum_post_delete(request):
    """Supprime d√©finitivement un post."""
    is_valid, discord_user_id, discord_name, is_legacy = await _auth_request(request, "/api/forum-post/delete")
    if not is_valid:
        return _with_cors(request, web.json_response({"ok": False, "error": "Invalid API key"}, status=401))
    
    try:
        body = await request.json()
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur lecture body suppression: {e}")
        body = {}
    
    thread_id = (body.get("threadId") or body.get("thread_id") or "").strip()
    post_id = (body.get("postId") or body.get("post_id") or body.get("id") or "").strip()
    post_title = (body.get("postTitle") or body.get("title") or "").strip()
    reason = (body.get("reason") or "").strip()
    
    logger.info(f"üóëÔ∏è Suppression post: {post_title or post_id} (thread={thread_id}, raison={reason or 'N/A'})")
    
    if not thread_id:
        # Pas de thread Discord : succ√®s sans appeler Discord (suppression historique/base uniquement)
        if post_id:
            # üî• SUPPRESSION SUPABASE
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, _delete_from_supabase_sync, None, post_id)
        return _with_cors(request, web.json_response({"ok": True, "skipped_discord": True}))
    
    async with aiohttp.ClientSession() as session:
        deleted, status = await _discord_delete_channel(session, thread_id)
        
        if not deleted:
            if status == 404:
                logger.info(f"‚ÑπÔ∏è Thread d√©j√† supprim√©: {thread_id}")
                # üî• SUPPRESSION SUPABASE
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, _delete_from_supabase_sync, thread_id, post_id)
                return _with_cors(request, web.json_response({"ok": False, "error": "Thread introuvable (d√©j√† supprim√© ?)", "not_found": True}, status=404))
            logger.warning(f"‚ö†Ô∏è √âchec suppression thread Discord: {thread_id} (status={status})")
            return _with_cors(request, web.json_response({"ok": False, "error": "√âchec suppression du thread sur Discord"}, status=500))
        
        # üî• SUPPRESSION SUPABASE
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, _delete_from_supabase_sync, thread_id, post_id)
        
        # üî• Envoyer l'annonce de suppression dans le salon Discord
        if post_title:  # Seulement si on a un titre
            discord_url = body.get("discordUrl") or body.get("discord_url") or body.get("thread_url") or ""
            await _send_deletion_announcement(session, post_title, reason, thread_url=discord_url)
    
    logger.info(f"‚úÖ Post supprim√© compl√®tement: {post_title or thread_id}")
    return _with_cors(request, web.json_response({"ok": True, "thread_id": thread_id}))

# ==================== SUPPRESSION DE COMPTE ====================

def _delete_account_data_sync(user_id: str) -> dict:
    """
    Supprime toutes les donn√©es personnelles d'un utilisateur (sync).
    Retourne un dict avec le d√©tail des suppressions et log un r√©sum√© global.
    """
    sb = _get_supabase()
    if not sb:
        return {"ok": False, "error": "Client Supabase non initialis√©"}

    results = {}
    
    # 1) Autorisations d'√©dition (propri√©taire ET √©diteur)
    try:
        sb.table("allowed_editors").delete().eq("owner_id", user_id).execute()
        sb.table("allowed_editors").delete().eq("editor_id", user_id).execute()
        results["allowed_editors"] = "ok"
    except Exception as e:
        results["allowed_editors"] = f"erreur: {e}"
        logger.warning(f"‚ö†Ô∏è [delete_account] allowed_editors: {e}")

    # 2) Instructions sauvegard√©es
    try:
        sb.table("saved_instructions").delete().eq("owner_id", user_id).execute()
        results["saved_instructions"] = "ok"
    except Exception as e:
        results["saved_instructions"] = f"erreur: {e}"
        logger.warning(f"‚ö†Ô∏è [delete_account] saved_instructions: {e}")

    # 3) Templates sauvegard√©s
    try:
        sb.table("saved_templates").delete().eq("owner_id", user_id).execute()
        results["saved_templates"] = "ok"
    except Exception as e:
        results["saved_templates"] = f"erreur: {e}"
        logger.warning(f"‚ö†Ô∏è [delete_account] saved_templates: {e}")

    # 4) Profil utilisateur
    try:
        sb.table("profiles").delete().eq("id", user_id).execute()
        results["profile"] = "ok"
    except Exception as e:
        results["profile"] = f"erreur: {e}"
        logger.warning(f"‚ö†Ô∏è [delete_account] profile: {e}")

    # 5) Suppression du compte Auth (n√©cessite service role key)
    try:
        sb.auth.admin.delete_user(user_id)
        results["auth_user"] = "ok"
    except Exception as e:
        results["auth_user"] = f"erreur: {e}"
        logger.error(f"‚ùå [delete_account] √âchec suppression compte Auth ({user_id}): {e}")

    # --- NOUVEAU : Log global de synth√®se ---
    success_count = sum(1 for status in results.values() if status == "ok")
    total_steps = len(results)
    is_fully_deleted = success_count == total_steps

    summary_msg = f"üìä [RESUM√â SUPPRESSION] User: {user_id} | {success_count}/{total_steps} √©tapes r√©ussies"
    
    if is_fully_deleted:
        logger.info(f"‚úÖ {summary_msg}")
    else:
        # On liste les tables qui ont √©chou√© pour un diagnostic rapide
        failed_tables = [table for table, status in results.items() if status != "ok"]
        logger.error(f"‚ùå {summary_msg} | √âchecs sur: {', '.join(failed_tables)}")

    return {
        "ok": results.get("auth_user") == "ok", 
        "fully_cleared": is_fully_deleted,
        "details": results
    }

async def account_delete(request):
    """
    Supprime d√©finitivement le compte d'un utilisateur.
    Prot√©g√© par X-API-KEY (nouvelle cl√© individuelle + fallback legacy).
    Body JSON attendu : { "user_id": "<uuid>" }
    """
    is_valid, _, _, _ = await _auth_request(request, "/api/account/delete")
    if not is_valid:
        return _with_cors(
            request,
            web.json_response({"ok": False, "error": "Invalid API key"}, status=401)
        )

    try:
        body = await request.json()
    except Exception:
        return _with_cors(
            request,
            web.json_response({"ok": False, "error": "Body JSON invalide"}, status=400)
        )

    user_id = (body.get("user_id") or "").strip()
    if not user_id:
        return _with_cors(
            request,
            web.json_response({"ok": False, "error": "user_id requis"}, status=400)
        )

    logger.info(f"üóëÔ∏è [delete_account] Suppression demand√©e pour user_id={user_id}")

    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(None, _delete_account_data_sync, user_id)

    if not result["ok"]:
        logger.error(f"‚ùå [delete_account] √âchec: {result}")
        return _with_cors(
            request,
            web.json_response(
                {"ok": False, "error": "√âchec suppression du compte", "details": result.get("details")},
                status=500
            )
        )

    logger.info(f"‚úÖ [delete_account] Compte supprim√©: {user_id} | D√©tails: {result['details']}")
    return _with_cors(request, web.json_response({"ok": True, "details": result["details"]}))

# ==================== HANDLER 404 EXPLICITE ====================
async def handle_404(request):
    """Catch-all : logge toutes les routes inconnues pour fail2ban."""
    client_ip = _get_client_ip(request)
    user_id = _get_user_id(request)
    raw_key = (request.headers.get("X-API-KEY") or "").strip()
    key_hint = raw_key[:8] + "..." if len(raw_key) > 8 else "NOKEY"

    logger.warning(
        f"[HTTP_ERROR] {client_ip} | {user_id} | {key_hint} | "
        f"{request.method} {request.path} | STATUS=404"
    )
    return _with_cors(request, web.json_response({"error": "Not found"}, status=404))

# ==================== APPLICATION WEB ====================
app = web.Application(middlewares=[logging_middleware])
app.add_routes([
    web.get('/api/publisher/health', health),
    web.get('/api/jeux', get_jeux),
    web.post('/api/forum-post', forum_post),
    web.post('/api/forum-post/update', forum_post_update),
    web.post('/api/forum-post/delete', forum_post_delete),
    web.get('/api/history', get_history),
    web.post('/api/configure', configure),
    web.options('/{tail:.*}', options_handler),
    web.route('*', '/{tail:.*}', handle_404),
])

# ==================== LANCEMENT ====================
async def start_web_server():
    """Lance le serveur web API REST"""
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', config.PORT)
    await site.start()
    logger.info(f"üåê API REST d√©marr√©e sur le port {config.PORT}")

async def main():
    """Point d'entr√©e principal - Lance bot Discord + API REST en parall√®le"""
    # Lancer le serveur web
    await start_web_server()
    
    # Lancer le bot Discord
    await bot.start(config.PUBLISHER_DISCORD_TOKEN)

if __name__ == '__main__':
    from discord.http import Route
    Route.BASE = "https://discord.com/api"
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("üëã Arr√™t du bot...")
